{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaikadish/imdbProject/blob/main/model_training_and_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mUUcV7RDjs2",
        "outputId": "c3b1db78-3670-458a-c946-3be51320fb5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/GitHub/IMDB_project/imdbProject\n"
          ]
        }
      ],
      "source": [
        "# Mount to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/GitHub/IMDB_project/imdbProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HnjHKoQK_wpA"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "b7a81731b79d4affb069737539f50562",
            "3bda0785d4b643d8a0c0ff41efd9861c",
            "d2a6485ff8024b278c0de3fd792857ff",
            "a3581f5d05354c1cb2fec0c7877e4fac",
            "298873d1acac47d5b114ec9dce845b40",
            "d79a6c19daaf4862953634c13194e7e1",
            "012ebd6540794446b430c582a712f3e6",
            "7e71a6ba692648f084387967d898b6d4",
            "aac9f2038ac84a82a77e57c66eda6917",
            "73c070634bb04fab8c8d4c2cc83c5c82",
            "2ea2880762af409384c58e345a951e5a",
            "801a6b0df9a347abaacc38931af79e82",
            "77d6447ff47a4b6c8c2a58253ea768a8",
            "6c4ddeb3699a4aea849d57f68f423b05",
            "b6d4281c611240e38715efb6b1284620",
            "933011ae69704e1297bb3953a5e9a543",
            "9d529a96bc7d4ce894ddc98eaffea866",
            "57b8222297794e5aa25f8debc606d0be",
            "3e18ba1196254c59acd076df7c5a456e",
            "0c1e90f7db8e4eabac39d8d930320305",
            "b82d73791d6d422180629f637bd414ee",
            "b8f5f3a4f05841498db5857d5551bd02",
            "609c1ba7e3ad492e9a7f1b0d5c8e6afc",
            "8358740ec15a4bb6884cff13182fad62",
            "b0867e0e5aaf406ca1d3467c84fb3132",
            "196d5c26bb8749f1a9343628afe37e5f",
            "3f25bb7951a045e68eef80217a37542e",
            "f7d000c5ab1747f3847b89cd8a9d6f84",
            "d1b7bb82a21040aeb2c19d0d9ff07da2",
            "aeaaeea72e77421aa54a8f41f6d3bded",
            "6312ad1b234e48919dd4c0a3781f0f7e",
            "38a711f8cb914dd9903bae5baabbf027",
            "c5919308b7034a8ebf631db08aba3f09"
          ]
        },
        "id": "bpX_HUIUCRTr",
        "outputId": "f27b1916-255c-4763-de93-5b112701c99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7a81731b79d4affb069737539f50562"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "801a6b0df9a347abaacc38931af79e82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/321 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "609c1ba7e3ad492e9a7f1b0d5c8e6afc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('fabriceyhc/bert-base-uncased-imdb', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i9cFzFfQDWtm"
      },
      "outputs": [],
      "source": [
        "review_data=pd.read_csv('review_data_learning.csv')\n",
        "reviews=review_data['0'].to_list()\n",
        "ratings=review_data['1'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I9oRNxzDtcB",
        "outputId": "f98f8fc6-6ae0-4c54-d4cc-085013983e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[101, 2004, 1037, 2143, 7089, 1045, 2064, 1005, 1056, 2393, 24256, 9107, 1996, 18804, 2143, 2466, 2023, 2143, 2003, 1012, 2023, 2003, 1996, 2472, 1005, 1055, 14822, 2000, 2010, 2219, 2397, 2388, 1010, 2029, 4265, 2013, 21901, 1005, 1055, 4295, 1012, 2002, 1005, 1055, 2478, 2010, 2219, 7436, 4222, 2143, 2013, 2889, 1010, 1000, 2336, 1997, 3267, 1000, 2004, 1037, 2067, 7265, 6199, 2005, 1996, 2466, 1010, 2029, 2191, 2149, 2514, 1996, 2693, 2003, 1037, 4516, 1010, 2030, 2012, 2560, 1037, 2995, 2466, 1012, 9588, 2175, 3995, 2003, 3225, 2125, 2007, 2019, 6429, 18804, 3325, 1010, 2007, 1037, 2143, 9338, 10886, 2010, 2143, 2012, 1037, 6765, 1010, 4760, 1996, 3193, 2013, 2307, 12113, 1012, 1996, 12127, 2044, 11682, 4455, 2010, 3080, 2388, 1010, 3225, 2000, 9015, 2013, 21901, 1005, 1055, 11703, 19500, 3974, 2491, 1010, 2021, 2025, 2079, 2172, 2008, 2016, 3475, 1005, 1056, 2583, 2000, 2131, 2041, 1997, 4390, 2145, 1012, 1998, 2023, 3475, 1005, 1056, 1996, 2143, 11153, 2069, 3291, 1012, 1996, 2479, 2594, 4610, 2003, 2006, 2009, 1005, 1055, 2126, 2000, 1037, 5325, 1010, 1998, 1996, 2143, 9338, 2003, 13417, 2008, 14024, 2111, 4995, 1005, 1056, 2205, 2172, 2046, 2010, 5691, 1012, 9588, 2003, 2183, 2046, 24034, 1998, 2515, 4795, 2477, 1010, 2096, 1996, 2143, 9338, 1010, 2010, 2564, 1998, 2010, 5208, 2024, 2183, 12264, 2108, 5496, 1997, 11065, 6309, 1998, 15565, 1012, 2023, 2003, 1037, 2143, 2038, 2054, 1045, 2052, 5136, 18783, 2537, 3643, 1012, 17950, 6361, 1010, 2007, 1037, 8403, 3048, 4950, 6028, 1010, 2206, 1996, 2895, 1999, 1037, 2126, 1045, 2428, 2066, 1012, 1996, 2143, 2003, 1037, 4038, 2004, 2092, 2004, 2108, 1037, 18804, 2143, 1998, 1037, 18312, 2058, 1996, 14024, 3361, 5325, 2004, 2092, 2004, 2058, 1996, 10399, 14194, 2143, 3068, 1012, 1045, 2052, 26268, 2023, 2004, 18312, 2007, 1037, 3809, 5995, 1012, 19031, 2102, 2497, 3501, 16415, 10623, 1047, 6460, 6392, 2003, 8235, 2135, 2652, 1996, 2388, 1010, 3228, 1996, 8605, 2016, 1005, 1055, 3071, 1005, 1055, 2219, 7133, 1012, 2016, 2003, 11065, 1996, 3898, 2004, 1037, 6047, 1998, 17026, 3770, 2095, 2214, 2450, 1010, 3974, 6218, 1997, 2613, 3723, 1012, 2823, 2061, 4086, 1998, 8403, 1010, 2021, 16723, 1010, 14386, 4630, 1998, 22939, 18647, 2389, 1996, 2279, 1012, 1045, 2052, 16755, 2023, 2143, 2005, 8192, 1999, 2816, 2030, 4896, 4252, 2055, 9750, 6114, 2013, 2367, 5711, 1997, 21901, 1005, 1055, 11703, 19500, 1012, 2045, 1005, 1055, 2042, 2195, 2081, 1010, 2021, 2023, 2003, 2011, 2521, 1996, 2190, 1010, 4760, 1037, 2898, 2846, 1997, 8030, 2013, 1996, 11703, 19500, 1010, 2130, 1996, 6245, 2015, 1998, 6724, 2015, 2206, 2009, 1010, 2464, 2013, 2119, 2014, 1998, 1996, 2155, 1005, 1055, 3233, 1012, 2178, 2742, 1997, 1996, 2307, 3152, 2746, 2013, 1996, 2479, 2594, 3185, 3068, 1010, 2182, 1999, 3361, 5792, 2007, 5120, 1010, 2307, 3725, 1010, 4701, 1998, 2762, 1012, 10424, 2072, 29668, 15564, 1101, 2953, 10424, 2072, 29668, 15564, 7092, 2038, 2081, 1037, 2540, 9028, 6562, 2143, 2295, 2145, 6057, 1998, 2130, 2061, 6517, 2012, 2335, 1012, 2023, 2143, 2001, 4222, 1996, 14024, 4018, 2005, 1996, 6640, 4103, 2914, 2982, 1010, 2021, 2134, 102]\n",
            " Original:  [CLS] As a film lover I can't help immensely enjoying the meta film story this film is [SEP] This is the director's homage to his own late mother, which suffered from Alzheimer's disease [SEP] He's using his own Oscar nominated film from 1991, \"Children Of Nature\" as a backdraft for the story, which make us feel the move is a documentary, or at least a true story [SEP]Mama Gogo is starting off with an amazing meta experience, with a film maker presenting his film at a premiere, showing the view from great angles [SEP] The filmmaker after wards calls his older mother, starting to suffer from Alzheimer's decease losing control, but not do much that she isn't able to get out of trouble still [SEP] And this isn't the film makers only problem [SEP] The Islandic economy is on it's way to a crisis, and the film maker is experiencing that Icelandic people aren't too much into his movies [SEP] Mama is going into oblivion and does dangerous things, while the film maker, his wife and his sisters are going nuts being accused of stealing keys and jewels [SEP]This is a film has what I would consider fabulous production value [SEP] Beautifully filmed, with a lovely moving camera technique, following the action in a way I really like [SEP] The film is a comedy as well as being a meta film and a satire over the Icelandic financial crisis as well as over the Icelanduc film industry [SEP] I would classify this as satire with a serious depth [SEP]Kristbjørg Kjeld is brilliantly playing the mother, giving the impression she's everyone's own grandmother [SEP] She is stealing the screen as a smart and vibrant 80 year old woman, losing grip of realty [SEP] Sometimes so sweet and lovely, but accusing, deviant and diabolical the next [SEP]I would recommend this film for usage in schools or institutions teaching about elderly suffering from different stages of Alzheimer's decease [SEP] There's been several made, but this is by far the best, showing a wide range of symptoms from the decease,even the depressions and confusions following it, seen from both her and the family's stand [SEP]Another example of the great films coming from the Islandic movie industry, here in financial collaboration with Norway, Great Britain, Sweden and Germany [SEP] Friðrik Þór Friðriksson has made a heartwarming film though still funny and even so sad at times [SEP] This film was nominated the Icelandic candidate for the 83rd Academy Awards, but didn't make the final short list [SEP] It should have![PAD]\n",
            "Tokenized:  ['[CLS]', 'as', 'a', 'film', 'lover', 'i', 'can', \"'\", 't', 'help', 'immensely', 'enjoying', 'the', 'meta', 'film', 'story', 'this', 'film', 'is', '[SEP]', 'this', 'is', 'the', 'director', \"'\", 's', 'homage', 'to', 'his', 'own', 'late', 'mother', ',', 'which', 'suffered', 'from', 'alzheimer', \"'\", 's', 'disease', '[SEP]', 'he', \"'\", 's', 'using', 'his', 'own', 'oscar', 'nominated', 'film', 'from', '1991', ',', '\"', 'children', 'of', 'nature', '\"', 'as', 'a', 'back', '##dra', '##ft', 'for', 'the', 'story', ',', 'which', 'make', 'us', 'feel', 'the', 'move', 'is', 'a', 'documentary', ',', 'or', 'at', 'least', 'a', 'true', 'story', '[SEP]', 'mama', 'go', '##go', 'is', 'starting', 'off', 'with', 'an', 'amazing', 'meta', 'experience', ',', 'with', 'a', 'film', 'maker', 'presenting', 'his', 'film', 'at', 'a', 'premiere', ',', 'showing', 'the', 'view', 'from', 'great', 'angles', '[SEP]', 'the', 'filmmaker', 'after', 'wards', 'calls', 'his', 'older', 'mother', ',', 'starting', 'to', 'suffer', 'from', 'alzheimer', \"'\", 's', 'dec', '##ease', 'losing', 'control', ',', 'but', 'not', 'do', 'much', 'that', 'she', 'isn', \"'\", 't', 'able', 'to', 'get', 'out', 'of', 'trouble', 'still', '[SEP]', 'and', 'this', 'isn', \"'\", 't', 'the', 'film', 'makers', 'only', 'problem', '[SEP]', 'the', 'island', '##ic', 'economy', 'is', 'on', 'it', \"'\", 's', 'way', 'to', 'a', 'crisis', ',', 'and', 'the', 'film', 'maker', 'is', 'experiencing', 'that', 'icelandic', 'people', 'aren', \"'\", 't', 'too', 'much', 'into', 'his', 'movies', '[SEP]', 'mama', 'is', 'going', 'into', 'oblivion', 'and', 'does', 'dangerous', 'things', ',', 'while', 'the', 'film', 'maker', ',', 'his', 'wife', 'and', 'his', 'sisters', 'are', 'going', 'nuts', 'being', 'accused', 'of', 'stealing', 'keys', 'and', 'jewels', '[SEP]', 'this', 'is', 'a', 'film', 'has', 'what', 'i', 'would', 'consider', 'fabulous', 'production', 'value', '[SEP]', 'beautifully', 'filmed', ',', 'with', 'a', 'lovely', 'moving', 'camera', 'technique', ',', 'following', 'the', 'action', 'in', 'a', 'way', 'i', 'really', 'like', '[SEP]', 'the', 'film', 'is', 'a', 'comedy', 'as', 'well', 'as', 'being', 'a', 'meta', 'film', 'and', 'a', 'satire', 'over', 'the', 'icelandic', 'financial', 'crisis', 'as', 'well', 'as', 'over', 'the', 'iceland', '##uc', 'film', 'industry', '[SEP]', 'i', 'would', 'classify', 'this', 'as', 'satire', 'with', 'a', 'serious', 'depth', '[SEP]', 'kris', '##t', '##b', '##j', '##ø', '##rg', 'k', '##je', '##ld', 'is', 'brilliant', '##ly', 'playing', 'the', 'mother', ',', 'giving', 'the', 'impression', 'she', \"'\", 's', 'everyone', \"'\", 's', 'own', 'grandmother', '[SEP]', 'she', 'is', 'stealing', 'the', 'screen', 'as', 'a', 'smart', 'and', 'vibrant', '80', 'year', 'old', 'woman', ',', 'losing', 'grip', 'of', 'real', '##ty', '[SEP]', 'sometimes', 'so', 'sweet', 'and', 'lovely', ',', 'but', 'accusing', ',', 'devi', '##ant', 'and', 'dia', '##bolic', '##al', 'the', 'next', '[SEP]', 'i', 'would', 'recommend', 'this', 'film', 'for', 'usage', 'in', 'schools', 'or', 'institutions', 'teaching', 'about', 'elderly', 'suffering', 'from', 'different', 'stages', 'of', 'alzheimer', \"'\", 's', 'dec', '##ease', '[SEP]', 'there', \"'\", 's', 'been', 'several', 'made', ',', 'but', 'this', 'is', 'by', 'far', 'the', 'best', ',', 'showing', 'a', 'wide', 'range', 'of', 'symptoms', 'from', 'the', 'dec', '##ease', ',', 'even', 'the', 'depression', '##s', 'and', 'confusion', '##s', 'following', 'it', ',', 'seen', 'from', 'both', 'her', 'and', 'the', 'family', \"'\", 's', 'stand', '[SEP]', 'another', 'example', 'of', 'the', 'great', 'films', 'coming', 'from', 'the', 'island', '##ic', 'movie', 'industry', ',', 'here', 'in', 'financial', 'collaboration', 'with', 'norway', ',', 'great', 'britain', ',', 'sweden', 'and', 'germany', '[SEP]', 'fr', '##i', '##ð', '##rik', 'þ', '##or', 'fr', '##i', '##ð', '##rik', '##sson', 'has', 'made', 'a', 'heart', '##war', '##ming', 'film', 'though', 'still', 'funny', 'and', 'even', 'so', 'sad', 'at', 'times', '[SEP]', 'this', 'film', 'was', 'nominated', 'the', 'icelandic', 'candidate', 'for', 'the', '83', '##rd', 'academy', 'awards', ',', 'but', 'didn', \"'\", 't', 'make', 'the', 'final', 'short', 'list', '[SEP]', 'it', 'should', 'have', '!', '[PAD]']\n",
            "Token IDs:  [101, 2004, 1037, 2143, 7089, 1045, 2064, 1005, 1056, 2393, 24256, 9107, 1996, 18804, 2143, 2466, 2023, 2143, 2003, 102, 2023, 2003, 1996, 2472, 1005, 1055, 14822, 2000, 2010, 2219, 2397, 2388, 1010, 2029, 4265, 2013, 21901, 1005, 1055, 4295, 102, 2002, 1005, 1055, 2478, 2010, 2219, 7436, 4222, 2143, 2013, 2889, 1010, 1000, 2336, 1997, 3267, 1000, 2004, 1037, 2067, 7265, 6199, 2005, 1996, 2466, 1010, 2029, 2191, 2149, 2514, 1996, 2693, 2003, 1037, 4516, 1010, 2030, 2012, 2560, 1037, 2995, 2466, 102, 9588, 2175, 3995, 2003, 3225, 2125, 2007, 2019, 6429, 18804, 3325, 1010, 2007, 1037, 2143, 9338, 10886, 2010, 2143, 2012, 1037, 6765, 1010, 4760, 1996, 3193, 2013, 2307, 12113, 102, 1996, 12127, 2044, 11682, 4455, 2010, 3080, 2388, 1010, 3225, 2000, 9015, 2013, 21901, 1005, 1055, 11703, 19500, 3974, 2491, 1010, 2021, 2025, 2079, 2172, 2008, 2016, 3475, 1005, 1056, 2583, 2000, 2131, 2041, 1997, 4390, 2145, 102, 1998, 2023, 3475, 1005, 1056, 1996, 2143, 11153, 2069, 3291, 102, 1996, 2479, 2594, 4610, 2003, 2006, 2009, 1005, 1055, 2126, 2000, 1037, 5325, 1010, 1998, 1996, 2143, 9338, 2003, 13417, 2008, 14024, 2111, 4995, 1005, 1056, 2205, 2172, 2046, 2010, 5691, 102, 9588, 2003, 2183, 2046, 24034, 1998, 2515, 4795, 2477, 1010, 2096, 1996, 2143, 9338, 1010, 2010, 2564, 1998, 2010, 5208, 2024, 2183, 12264, 2108, 5496, 1997, 11065, 6309, 1998, 15565, 102, 2023, 2003, 1037, 2143, 2038, 2054, 1045, 2052, 5136, 18783, 2537, 3643, 102, 17950, 6361, 1010, 2007, 1037, 8403, 3048, 4950, 6028, 1010, 2206, 1996, 2895, 1999, 1037, 2126, 1045, 2428, 2066, 102, 1996, 2143, 2003, 1037, 4038, 2004, 2092, 2004, 2108, 1037, 18804, 2143, 1998, 1037, 18312, 2058, 1996, 14024, 3361, 5325, 2004, 2092, 2004, 2058, 1996, 10399, 14194, 2143, 3068, 102, 1045, 2052, 26268, 2023, 2004, 18312, 2007, 1037, 3809, 5995, 102, 19031, 2102, 2497, 3501, 16415, 10623, 1047, 6460, 6392, 2003, 8235, 2135, 2652, 1996, 2388, 1010, 3228, 1996, 8605, 2016, 1005, 1055, 3071, 1005, 1055, 2219, 7133, 102, 2016, 2003, 11065, 1996, 3898, 2004, 1037, 6047, 1998, 17026, 3770, 2095, 2214, 2450, 1010, 3974, 6218, 1997, 2613, 3723, 102, 2823, 2061, 4086, 1998, 8403, 1010, 2021, 16723, 1010, 14386, 4630, 1998, 22939, 18647, 2389, 1996, 2279, 102, 1045, 2052, 16755, 2023, 2143, 2005, 8192, 1999, 2816, 2030, 4896, 4252, 2055, 9750, 6114, 2013, 2367, 5711, 1997, 21901, 1005, 1055, 11703, 19500, 102, 2045, 1005, 1055, 2042, 2195, 2081, 1010, 2021, 2023, 2003, 2011, 2521, 1996, 2190, 1010, 4760, 1037, 2898, 2846, 1997, 8030, 2013, 1996, 11703, 19500, 1010, 2130, 1996, 6245, 2015, 1998, 6724, 2015, 2206, 2009, 1010, 2464, 2013, 2119, 2014, 1998, 1996, 2155, 1005, 1055, 3233, 102, 2178, 2742, 1997, 1996, 2307, 3152, 2746, 2013, 1996, 2479, 2594, 3185, 3068, 1010, 2182, 1999, 3361, 5792, 2007, 5120, 1010, 2307, 3725, 1010, 4701, 1998, 2762, 102, 10424, 2072, 29668, 15564, 1101, 2953, 10424, 2072, 29668, 15564, 7092, 2038, 2081, 1037, 2540, 9028, 6562, 2143, 2295, 2145, 6057, 1998, 2130, 2061, 6517, 2012, 2335, 102, 2023, 2143, 2001, 4222, 1996, 14024, 4018, 2005, 1996, 6640, 4103, 2914, 2982, 1010, 2021, 2134, 1005, 1056, 2191, 1996, 2345, 2460, 2862, 102, 2009, 2323, 2031, 999, 0]\n"
          ]
        }
      ],
      "source": [
        "review=review_data.iloc[0,0]\n",
        "\n",
        "print(tokenizer.encode(review, add_special_tokens=True,max_length=512,truncation=True))\n",
        "# NEED TO PROCESS DATA TO BE <512 WORDS IN LENGTH.\n",
        "review='[CLS] '+review.replace('.',' [SEP]')+'[PAD]'\n",
        "# Print the original sentence.\n",
        "print(' Original: ', review)\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(review))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(review)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxb1rMxIzng-",
        "outputId": "133b8ad6-355d-4769-b3e0-9693728181d7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  As a film lover I can't help immensely enjoying the meta film story this film is. This is the director's homage to his own late mother, which suffered from Alzheimer's disease. He's using his own Oscar nominated film from 1991, \"Children Of Nature\" as a backdraft for the story, which make us feel the move is a documentary, or at least a true story.Mama Gogo is starting off with an amazing meta experience, with a film maker presenting his film at a premiere, showing the view from great angles. The filmmaker after wards calls his older mother, starting to suffer from Alzheimer's decease losing control, but not do much that she isn't able to get out of trouble still. And this isn't the film makers only problem. The Islandic economy is on it's way to a crisis, and the film maker is experiencing that Icelandic people aren't too much into his movies. Mama is going into oblivion and does dangerous things, while the film maker, his wife and his sisters are going nuts being accused of stealing keys and jewels.This is a film has what I would consider fabulous production value. Beautifully filmed, with a lovely moving camera technique, following the action in a way I really like. The film is a comedy as well as being a meta film and a satire over the Icelandic financial crisis as well as over the Icelanduc film industry. I would classify this as satire with a serious depth.Kristbjørg Kjeld is brilliantly playing the mother, giving the impression she's everyone's own grandmother. She is stealing the screen as a smart and vibrant 80 year old woman, losing grip of realty. Sometimes so sweet and lovely, but accusing, deviant and diabolical the next.I would recommend this film for usage in schools or institutions teaching about elderly suffering from different stages of Alzheimer's decease. There's been several made, but this is by far the best, showing a wide range of symptoms from the decease,even the depressions and confusions following it, seen from both her and the family's stand.Another example of the great films coming from the Islandic movie industry, here in financial collaboration with Norway, Great Britain, Sweden and Germany. Friðrik Þór Friðriksson has made a heartwarming film though still funny and even so sad at times. This film was nominated the Icelandic candidate for the 83rd Academy Awards, but didn't make the final short list. It should have!\n",
            "Token IDs: tensor([  101,  2004,  1037,  2143,  7089,  1045,  2064,  1005,  1056,  2393,\n",
            "        24256,  9107,  1996, 18804,  2143,  2466,  2023,  2143,  2003,  1012,\n",
            "         2023,  2003,  1996,  2472,  1005,  1055, 14822,  2000,  2010,  2219,\n",
            "         2397,  2388,  1010,  2029,  4265,  2013, 21901,  1005,  1055,  4295,\n",
            "         1012,  2002,  1005,  1055,  2478,  2010,  2219,  7436,  4222,  2143,\n",
            "         2013,  2889,  1010,  1000,  2336,  1997,  3267,  1000,  2004,  1037,\n",
            "         2067,  7265,  6199,  2005,  1996,  2466,  1010,  2029,  2191,  2149,\n",
            "         2514,  1996,  2693,  2003,  1037,  4516,  1010,  2030,  2012,  2560,\n",
            "         1037,  2995,  2466,  1012,  9588,  2175,  3995,  2003,  3225,  2125,\n",
            "         2007,  2019,  6429, 18804,  3325,  1010,  2007,  1037,  2143,  9338,\n",
            "        10886,  2010,  2143,  2012,  1037,  6765,  1010,  4760,  1996,  3193,\n",
            "         2013,  2307, 12113,  1012,  1996, 12127,  2044, 11682,  4455,  2010,\n",
            "         3080,  2388,  1010,  3225,  2000,  9015,  2013, 21901,  1005,  1055,\n",
            "        11703, 19500,  3974,  2491,  1010,  2021,  2025,  2079,  2172,  2008,\n",
            "         2016,  3475,  1005,  1056,  2583,  2000,  2131,  2041,  1997,  4390,\n",
            "         2145,  1012,  1998,  2023,  3475,  1005,  1056,  1996,  2143, 11153,\n",
            "         2069,  3291,  1012,  1996,  2479,  2594,  4610,  2003,  2006,  2009,\n",
            "         1005,  1055,  2126,  2000,  1037,  5325,  1010,  1998,  1996,  2143,\n",
            "         9338,  2003, 13417,  2008, 14024,  2111,  4995,  1005,  1056,  2205,\n",
            "         2172,  2046,  2010,  5691,  1012,  9588,  2003,  2183,  2046, 24034,\n",
            "         1998,  2515,  4795,  2477,  1010,  2096,  1996,  2143,  9338,  1010,\n",
            "         2010,  2564,  1998,  2010,  5208,  2024,  2183, 12264,  2108,  5496,\n",
            "         1997, 11065,  6309,  1998, 15565,  1012,  2023,  2003,  1037,  2143,\n",
            "         2038,  2054,  1045,  2052,  5136, 18783,  2537,  3643,  1012, 17950,\n",
            "         6361,  1010,  2007,  1037,  8403,  3048,  4950,  6028,  1010,  2206,\n",
            "         1996,  2895,  1999,  1037,  2126,  1045,  2428,  2066,  1012,  1996,\n",
            "         2143,  2003,  1037,  4038,  2004,  2092,  2004,  2108,  1037, 18804,\n",
            "         2143,  1998,  1037, 18312,  2058,  1996, 14024,  3361,  5325,  2004,\n",
            "         2092,  2004,  2058,  1996, 10399, 14194,  2143,  3068,  1012,  1045,\n",
            "         2052, 26268,  2023,  2004, 18312,  2007,  1037,  3809,  5995,  1012,\n",
            "        19031,  2102,  2497,  3501, 16415, 10623,  1047,  6460,  6392,  2003,\n",
            "         8235,  2135,  2652,  1996,  2388,  1010,  3228,  1996,  8605,  2016,\n",
            "         1005,  1055,  3071,  1005,  1055,  2219,  7133,  1012,  2016,  2003,\n",
            "        11065,  1996,  3898,  2004,  1037,  6047,  1998, 17026,  3770,  2095,\n",
            "         2214,  2450,  1010,  3974,  6218,  1997,  2613,  3723,  1012,  2823,\n",
            "         2061,  4086,  1998,  8403,  1010,  2021, 16723,  1010, 14386,  4630,\n",
            "         1998, 22939, 18647,  2389,  1996,  2279,  1012,  1045,  2052, 16755,\n",
            "         2023,  2143,  2005,  8192,  1999,  2816,  2030,  4896,  4252,  2055,\n",
            "         9750,  6114,  2013,  2367,  5711,  1997, 21901,  1005,  1055, 11703,\n",
            "        19500,  1012,  2045,  1005,  1055,  2042,  2195,  2081,  1010,  2021,\n",
            "         2023,  2003,  2011,  2521,  1996,  2190,  1010,  4760,  1037,  2898,\n",
            "         2846,  1997,  8030,  2013,  1996, 11703, 19500,  1010,  2130,  1996,\n",
            "         6245,  2015,  1998,  6724,  2015,  2206,  2009,  1010,  2464,  2013,\n",
            "         2119,  2014,  1998,  1996,  2155,  1005,  1055,  3233,  1012,  2178,\n",
            "         2742,  1997,  1996,  2307,  3152,  2746,  2013,  1996,  2479,  2594,\n",
            "         3185,  3068,  1010,  2182,  1999,  3361,  5792,  2007,  5120,  1010,\n",
            "         2307,  3725,  1010,  4701,  1998,  2762,  1012, 10424,  2072, 29668,\n",
            "        15564,  1101,  2953, 10424,  2072, 29668, 15564,  7092,  2038,  2081,\n",
            "         1037,  2540,  9028,  6562,  2143,  2295,  2145,  6057,  1998,  2130,\n",
            "         2061,  6517,  2012,  2335,  1012,  2023,  2143,  2001,  4222,  1996,\n",
            "        14024,  4018,  2005,  1996,  6640,  4103,  2914,  2982,  1010,  2021,\n",
            "         2134,   102])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for review in reviews:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        review,                      # Sentence to encode.\n",
        "                        truncation=True,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.tensor(input_ids)\n",
        "attention_masks = torch.tensor(attention_masks)\n",
        "labels = torch.tensor(ratings)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', reviews[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyBvqQVL5_Xn",
        "outputId": "2057ac98-c9c7-43f9-d395-50ae72124333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117,344 training samples\n",
            "25,145 validation samples\n",
            "25,145 test samples\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.7 * len(dataset))+1\n",
        "val_size = int(0.5*(len(dataset) - train_size))\n",
        "test_size = int(0.5*(len(dataset) - train_size))\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size,test_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} test samples'.format(test_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AA6LOY3C8EIB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            shuffle=True,\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "52e_tWrOM0lI"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "outfile = open('val_dataloader','wb')\n",
        "pickle.dump(validation_dataloader,outfile)\n",
        "outfile.close()\n",
        "\n",
        "outfile = open('train_dataloader','wb')\n",
        "pickle.dump(train_dataloader,outfile)\n",
        "outfile.close()\n",
        "\n",
        "outfile = open('test_dataloader','wb')\n",
        "pickle.dump(test_dataloader,outfile)\n",
        "outfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y0Nt6wj6_hJQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "infile = open('val_dataloader','rb')\n",
        "validation_dataloader = pickle.load(infile)\n",
        "infile.close()\n",
        "\n",
        "infile = open('test_dataloader','rb')\n",
        "test_dataloader = pickle.load(infile)\n",
        "infile.close()\n",
        "\n",
        "infile = open('train_dataloader','rb')\n",
        "train_dataloader = pickle.load(infile)\n",
        "infile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5FHTMUiB-8K",
        "outputId": "07444c04-6402-421d-8725-40156b268e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels =  1, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8SZiP2skQIC",
        "outputId": "f2caa421-72cf-4745-95ec-bf3b4f53a090"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "pgmbwLIXE4Yp",
        "outputId": "a8ed4968-389a-4174-b52b-551a925da5ae"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5617a886ef39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                       return_dict=False)\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1552\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m         )\n\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.76 GiB total capacity; 13.27 GiB already allocated; 25.75 MiB free; 13.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  if step>4:\n",
        "    break\n",
        "\n",
        "  model.zero_grad()\n",
        "\n",
        "  b_input_ids = batch[0].cuda()\n",
        "  b_input_mask = batch[1].cuda()\n",
        "  b_labels = batch[2].cuda()\n",
        "  \n",
        "  loss, logits = model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask, \n",
        "                      labels=b_labels,\n",
        "                      return_dict=False)\n",
        "  print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "i4h6kLnPImyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf857512-937b-47dc-b373-e4ee6ada88a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8,  3,  9,  1,  5,  2,  9,  5,  5,  5,  7,  9,  3,  2, 10,  5],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "b_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ekE_U7LJj5HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF9lyfuGGGV9",
        "outputId": "2d83590c-01cc-4723-e5f5-d25de5f17d46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "123058176"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "t = torch.cuda.get_device_properties(0).total_memory\n",
        "r = torch.cuda.memory_reserved(0)\n",
        "a = torch.cuda.memory_allocated(0)\n",
        "f = r-a  # free inside reserved\n",
        "\n",
        "f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPGDgh_sG4LV",
        "outputId": "36b8ca72-92c2-4633-d576-bf255bf8aa43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 11 19:05:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W /  70W |  11898MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "abar6vwjGu8L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "be6879f8-81f9-4422-ef74-d0657864fee6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b0cec479cb08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "del model\n",
        "torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_training_and_testing",
      "provenance": [],
      "authorship_tag": "ABX9TyPyhDOyzhV9Lp2WbZj1XlON",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b7a81731b79d4affb069737539f50562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bda0785d4b643d8a0c0ff41efd9861c",
              "IPY_MODEL_d2a6485ff8024b278c0de3fd792857ff",
              "IPY_MODEL_a3581f5d05354c1cb2fec0c7877e4fac"
            ],
            "layout": "IPY_MODEL_298873d1acac47d5b114ec9dce845b40"
          }
        },
        "3bda0785d4b643d8a0c0ff41efd9861c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79a6c19daaf4862953634c13194e7e1",
            "placeholder": "​",
            "style": "IPY_MODEL_012ebd6540794446b430c582a712f3e6",
            "value": "Downloading: 100%"
          }
        },
        "d2a6485ff8024b278c0de3fd792857ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e71a6ba692648f084387967d898b6d4",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aac9f2038ac84a82a77e57c66eda6917",
            "value": 231508
          }
        },
        "a3581f5d05354c1cb2fec0c7877e4fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c070634bb04fab8c8d4c2cc83c5c82",
            "placeholder": "​",
            "style": "IPY_MODEL_2ea2880762af409384c58e345a951e5a",
            "value": " 226k/226k [00:00&lt;00:00, 2.81MB/s]"
          }
        },
        "298873d1acac47d5b114ec9dce845b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79a6c19daaf4862953634c13194e7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "012ebd6540794446b430c582a712f3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e71a6ba692648f084387967d898b6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aac9f2038ac84a82a77e57c66eda6917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73c070634bb04fab8c8d4c2cc83c5c82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea2880762af409384c58e345a951e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "801a6b0df9a347abaacc38931af79e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77d6447ff47a4b6c8c2a58253ea768a8",
              "IPY_MODEL_6c4ddeb3699a4aea849d57f68f423b05",
              "IPY_MODEL_b6d4281c611240e38715efb6b1284620"
            ],
            "layout": "IPY_MODEL_933011ae69704e1297bb3953a5e9a543"
          }
        },
        "77d6447ff47a4b6c8c2a58253ea768a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d529a96bc7d4ce894ddc98eaffea866",
            "placeholder": "​",
            "style": "IPY_MODEL_57b8222297794e5aa25f8debc606d0be",
            "value": "Downloading: 100%"
          }
        },
        "6c4ddeb3699a4aea849d57f68f423b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e18ba1196254c59acd076df7c5a456e",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c1e90f7db8e4eabac39d8d930320305",
            "value": 112
          }
        },
        "b6d4281c611240e38715efb6b1284620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b82d73791d6d422180629f637bd414ee",
            "placeholder": "​",
            "style": "IPY_MODEL_b8f5f3a4f05841498db5857d5551bd02",
            "value": " 112/112 [00:00&lt;00:00, 3.52kB/s]"
          }
        },
        "933011ae69704e1297bb3953a5e9a543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d529a96bc7d4ce894ddc98eaffea866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b8222297794e5aa25f8debc606d0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e18ba1196254c59acd076df7c5a456e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c1e90f7db8e4eabac39d8d930320305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b82d73791d6d422180629f637bd414ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8f5f3a4f05841498db5857d5551bd02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "609c1ba7e3ad492e9a7f1b0d5c8e6afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8358740ec15a4bb6884cff13182fad62",
              "IPY_MODEL_b0867e0e5aaf406ca1d3467c84fb3132",
              "IPY_MODEL_196d5c26bb8749f1a9343628afe37e5f"
            ],
            "layout": "IPY_MODEL_3f25bb7951a045e68eef80217a37542e"
          }
        },
        "8358740ec15a4bb6884cff13182fad62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7d000c5ab1747f3847b89cd8a9d6f84",
            "placeholder": "​",
            "style": "IPY_MODEL_d1b7bb82a21040aeb2c19d0d9ff07da2",
            "value": "Downloading: 100%"
          }
        },
        "b0867e0e5aaf406ca1d3467c84fb3132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeaaeea72e77421aa54a8f41f6d3bded",
            "max": 321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6312ad1b234e48919dd4c0a3781f0f7e",
            "value": 321
          }
        },
        "196d5c26bb8749f1a9343628afe37e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38a711f8cb914dd9903bae5baabbf027",
            "placeholder": "​",
            "style": "IPY_MODEL_c5919308b7034a8ebf631db08aba3f09",
            "value": " 321/321 [00:00&lt;00:00, 4.92kB/s]"
          }
        },
        "3f25bb7951a045e68eef80217a37542e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d000c5ab1747f3847b89cd8a9d6f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1b7bb82a21040aeb2c19d0d9ff07da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeaaeea72e77421aa54a8f41f6d3bded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6312ad1b234e48919dd4c0a3781f0f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38a711f8cb914dd9903bae5baabbf027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5919308b7034a8ebf631db08aba3f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
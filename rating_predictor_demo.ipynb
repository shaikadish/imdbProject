{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rating_predictor_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XwnqYtidM3LA"
      ],
      "authorship_tag": "ABX9TyOi9c4+3fc4BK1/ie6ilClP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaikadish/imdbProject/blob/main/rating_predictor_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to my Review Rating Predictor demo!\n",
        "\n",
        "This is a demo for an NLP model I trained to predict your rating of a movie (on a scale from 1-10) based on a review that you write for it. \n",
        "\n",
        "To run the demo, hover your mouse over the code block directly below and press the play button on the top left. The first time you run the demo, some files will be loaded, which can take a minute or two. Once the demo is running, you can type your film review in the box that appears at the bottom of the page, and then press enter to see the score that the model predicted. To run the demo again, just press the play button! Remember, the model performs best if you type longer reviews, so if it is giving nonsensical ratings from reviews like \"That movie sucked\" try fleshing out the review to get a more accurate rating.\n",
        "\n",
        "If you are interested in how I made this, please check out this [tutorial](https://github.com/shaikadish/imdbProject) I wrote which details the entire process!"
      ],
      "metadata": {
        "id": "XwnqYtidM3LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo:"
      ],
      "metadata": {
        "id": "segNszwYKiIJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RzydEXU90FM"
      },
      "outputs": [],
      "source": [
        "# I am remove all printed output. I don't want to scare any non-technical people!\n",
        "\n",
        "# Run setup only on first run\n",
        "if not('BertTokenizer' in locals()):\n",
        "  # Download model and library\n",
        "  print('Loading important things...')\n",
        "  !pip install transformers &> /dev/null\n",
        "  !gdown --id 1-00HNjkWgzq6_b-UDJtUfztR5Ga-Ymbi &> /dev/null\n",
        "\n",
        "  # Disable output watnings\n",
        "  import warnings\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "  # Import libraries\n",
        "  from transformers.utils.logging import disable_progress_bar\n",
        "  import torch\n",
        "  import torch.nn as nn\n",
        "  from transformers import BertTokenizer, AutoModel\n",
        "  import transformers\n",
        "  transformers.logging.set_verbosity_error()\n",
        "\n",
        "  # Model class\n",
        "  class RatingModel(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(RatingModel, self).__init__()\n",
        "          \n",
        "          # Load pretrained BERT model\n",
        "          self.base_model = AutoModel.from_pretrained('fabriceyhc/bert-base-uncased-imdb')\n",
        "          # Include dropout layer in classification head\n",
        "          self.dropout = nn.Dropout(0.5)\n",
        "          # Add new output layer for classification\n",
        "          self.linear = nn.Linear(768, 1) \n",
        "          \n",
        "      def forward(self, tokenized_reviews, attn_mask):\n",
        "\n",
        "          # Pass the tokenized reviews through the BERT model\n",
        "          outputs = self.base_model(tokenized_reviews, attention_mask=attn_mask)\n",
        "          outputs = self.dropout(outputs[0])\n",
        "\n",
        "          # The slicing of the BERT model outputs (bellow) is to make use of the BERT features \n",
        "          # from the only the special [CLS] token for classification. This token is at index 0\n",
        "          outputs = self.linear(outputs[:,0,:])\n",
        "          \n",
        "          return outputs\n",
        "\n",
        "  # Predictor class\n",
        "  class RatingPredictor():\n",
        "      def __init__(self,model,tokenizer):\n",
        "\n",
        "        # Load model and tokenizer\n",
        "        self.model = model.eval()\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "      def predict(self,review):\n",
        "\n",
        "        # Tokenize review\n",
        "        encoded_dict = self.tokenizer.encode_plus(\n",
        "                          review,                      \n",
        "                          truncation=True,\n",
        "                          add_special_tokens = True, \n",
        "                          max_length = 512,          \n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                                            )\n",
        "            \n",
        "        tokenized_review = encoded_dict['input_ids']\n",
        "        attention_mask = encoded_dict['attention_mask']\n",
        "\n",
        "        # Get rating prediction\n",
        "        preds = self.model(torch.tensor([tokenized_review]),torch.tensor([attention_mask]))\n",
        "\n",
        "        # Return rating out of 10\n",
        "        return round(preds.item()*10)\n",
        "\n",
        "  # Download tokenizer\n",
        "  tokenizer = BertTokenizer.from_pretrained('fabriceyhc/bert-base-uncased-imdb', do_lower_case=True,disable_progress_bar=True,disable_tqdm=True)\n",
        "  print(\"Almost Done...\")\n",
        "\n",
        "  # Create model and load\n",
        "  model = RatingModel()\n",
        "  model.load_state_dict(torch.load('imdb_1.pt',map_location=torch.device('cpu')))\n",
        "\n",
        "  # Create predictor\n",
        "  predictor = RatingPredictor(model,tokenizer)\n",
        "  print('Done!\\n')\n",
        "\n",
        "# Run demo\n",
        "review=input(\"Type a review: \\n\\n\")\n",
        "prediction=predictor.predict(review)\n",
        "print(f'\\nPredicted rating: {prediction}/10')"
      ]
    }
  ]
}
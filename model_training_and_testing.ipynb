{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaikadish/imdbProject/blob/main/model_training_and_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mUUcV7RDjs2",
        "outputId": "85acdf9b-3bf2-4a48-e8a4-966310a13128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/GitHub/IMDB_project/imdbProject\n"
          ]
        }
      ],
      "source": [
        "# Mount to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "%cd drive/MyDrive/GitHub/IMDB_project/imdbProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnjHKoQK_wpA",
        "outputId": "123e7a14-1b4d-48fa-ae45-7946e768a898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ignore"
      ],
      "metadata": {
        "id": "xVpOev2jsLYZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "906112e0be7f429abe568b7a9214445c",
            "897a1cdd8bdf4e27a1238b0b8a0815a3",
            "0bd341f61cd04355b181dd2acea22b15",
            "270da281a6864e9096eca830d874f651",
            "bbba5f407a3b482caf6fcc4577303810",
            "5d6bdf34b81e4c8980e0a2c93b7389c9",
            "5e453e68e6e042908b85671391874438",
            "2864b06d6a634bdc825a371b85c2b982",
            "725aca6f9e8f4d218d49443c6b223c04",
            "59195cc6b0fa42d18f1e61c077ec08fc",
            "8ee2b94292de4306b20d12095cc5e6d5",
            "431a32e586c24e4e829c60d50b814189",
            "957c331314104fe6b1414735d785cdb8",
            "f30ad49bae954144b2761408490ac98d",
            "10009b0caefa4071922efa05be6f4f7f",
            "65546b861ea94afcb33be9bb710c6df3",
            "d0f131e534114e039943075176dc0e35",
            "0b1abb19f21348bd84e0908f9dbebdd0",
            "1bc53f859d6b44989b5086b9cebac42a",
            "6ed8ed5f83974ae2a8fc1f988171587e",
            "7996d0958d1447888652cb367ef02ec6",
            "ab2414fdb9024792a171af41177ec089",
            "51cac2b690d449c9babd8713b8f87d0a",
            "05734230883840bfad594b807c9d95ce",
            "fefdd3b61848485497ec0f64e0bc680a",
            "218cb5cac3234846af57d7b6d3cb779a",
            "b2d177ccbb3f4096943295da6b94ae73",
            "23d49751bdb84826a889e6815e30aa48",
            "281b7351795048f39335c1de18df3d75",
            "9add6f55e9494a2696c2655ece60eb9e",
            "23596eb47542415d8eb20bac31cf438a",
            "62c1c9d71e134147915f43581c7e1df7",
            "71c59b54b2b04cbdbdb959f2a2d03496"
          ]
        },
        "id": "bpX_HUIUCRTr",
        "outputId": "d1bf5707-5d2f-405f-dfe4-fe918bf6439c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "906112e0be7f429abe568b7a9214445c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "431a32e586c24e4e829c60d50b814189"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/321 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51cac2b690d449c9babd8713b8f87d0a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('fabriceyhc/bert-base-uncased-imdb', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9cFzFfQDWtm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "88bced8d-8b51-4cc5-c7a4-b4ef2e3b0736"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dd9265d7bdd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreview_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'review_data_learning.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreview_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreview_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
          ]
        }
      ],
      "source": [
        "review_data=pd.read_csv('review_data_learning.csv')\n",
        "reviews=review_data['0'].to_list()\n",
        "ratings=review_data['1'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2I9oRNxzDtcB"
      },
      "outputs": [],
      "source": [
        "review=review_data.iloc[0,0]\n",
        "\n",
        "print(tokenizer.encode(review, add_special_tokens=True,max_length=512,truncation=True))\n",
        "# NEED TO PROCESS DATA TO BE <512 WORDS IN LENGTH.\n",
        "review='[CLS] '+review.replace('.',' [SEP]')+'[PAD]'\n",
        "# Print the original sentence.\n",
        "print(' Original: ', review)\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(review))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(review)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxb1rMxIzng-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for review in reviews:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        review,                      # Sentence to encode.\n",
        "                        truncation=True,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.tensor(input_ids)\n",
        "attention_masks = torch.tensor(attention_masks)\n",
        "labels = torch.tensor(ratings)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', reviews[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyBvqQVL5_Xn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.7 * len(dataset))+1\n",
        "val_size = int(0.5*(len(dataset) - train_size))\n",
        "test_size = int(0.5*(len(dataset) - train_size))\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size,test_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} test samples'.format(test_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA6LOY3C8EIB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            shuffle=True,\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52e_tWrOM0lI"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "outfile = open('val_dataloader','wb')\n",
        "pickle.dump(validation_dataloader,outfile)\n",
        "outfile.close()\n",
        "\n",
        "outfile = open('train_dataloader','wb')\n",
        "pickle.dump(train_dataloader,outfile)\n",
        "outfile.close()\n",
        "\n",
        "outfile = open('test_dataloader','wb')\n",
        "pickle.dump(test_dataloader,outfile)\n",
        "outfile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# continue"
      ],
      "metadata": {
        "id": "0EYRQqzrsQWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y0Nt6wj6_hJQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "infile = open('val_dataloader','rb')\n",
        "validation_dataloader = pickle.load(infile)\n",
        "infile.close()\n",
        "\n",
        "infile = open('test_dataloader','rb')\n",
        "test_dataloader = pickle.load(infile)\n",
        "infile.close()\n",
        "\n",
        "infile = open('train_dataloader','rb')\n",
        "train_dataloader = pickle.load(infile)\n",
        "infile.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class RatingModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RatingModel, self).__init__()\n",
        "        \n",
        "        self.base_model = AutoModel.from_pretrained('fabriceyhc/bert-base-uncased-imdb')\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.linear = nn.Linear(768, 1) # output features from bert is 768 and 2 is ur number of labels\n",
        "        \n",
        "    def forward(self, input_ids, attn_mask):\n",
        "        outputs = self.base_model(input_ids, attention_mask=attn_mask)\n",
        "        # You write you new head here\n",
        "        outputs = self.dropout(outputs[0])\n",
        "        outputs = self.linear(outputs[:,0,:])\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "model = RatingModel()\n",
        "model.cuda()\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "afbb6124bd9645b4a421f3b04fd5188b",
            "3279a0eb8d80442897ef37672419d6ce",
            "be68f72c05e146b1aeb427086ecda3b7",
            "895cfe45e2694195b32cc06b840924da",
            "7f7d68cb90c3466da2803842d92fc680",
            "50dec81c666448c895ae760c0e67edf5",
            "3874d0e6b13d48028d10887c2ff29f94",
            "5320741ce4834d218121bcb538a698c8",
            "84fcc1be04b14d2d921857459bbbb1fe",
            "88116fb495d34fdca0e923b0e2cc1be2",
            "de37f16538324664adbf322a823290c0",
            "0158b3f01b094d0c813f90ead328daf0",
            "44fb331bcafb49a99f95cebfccf13d72",
            "c239a240375b428d916d4b6728043417",
            "8fb1f09141b6405f957b5e9b080c1f9e",
            "9152fe9e09d04d6090819a910c6f0f02",
            "f52112e98aa14a308503f9a158fc16c7",
            "c2d85ee3f31f405ba896b34193b70b4f",
            "2d2cdbc6faf94a94894b5a53df4e4516",
            "82bdc76fcfcd49649a12efe18d51d3a0",
            "1501bcd8dd064f50aafd8c38dfbb46d4",
            "8c9b85a865f3475a8f1afff7d2625a94"
          ]
        },
        "id": "ZqdciuZwdTwX",
        "outputId": "826dd887-00b4-4146-a218-1f8863fbfebb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afbb6124bd9645b4a421f3b04fd5188b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0158b3f01b094d0c813f90ead328daf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at fabriceyhc/bert-base-uncased-imdb were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n"
      ],
      "metadata": {
        "id": "n5GsdHW-uoff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5FHTMUiB-8K"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels =  1, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "id": "q8SZiP2skQIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "H4-AYZuwkZHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "d2Tg9_lS1mM-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def r2_score(outputs, labels):\n",
        "    labels_mean = torch.mean(labels)\n",
        "    ss_tot = torch.sum((labels - labels_mean) ** 2)\n",
        "    ss_res = torch.sum((labels - outputs) ** 2)\n",
        "    r2 = 1 - ss_res / ss_tot\n",
        "    return r2"
      ],
      "metadata": {
        "id": "Rw-BfCYk4oAg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgmbwLIXE4Yp",
        "outputId": "1728ba4c-7c10-421f-8dff-1a06a2be85b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "  Batch 40  of  7334.    Elapsed: 0:00:33.    Training Loss: 0.23935628421604632.\n",
            "  Batch 80  of  7334.    Elapsed: 0:01:06.    Training Loss: 0.16844645007513465.\n",
            "  Batch 120  of  7334.    Elapsed: 0:01:39.    Training Loss: 0.13109115427359938.\n",
            "  Batch 160  of  7334.    Elapsed: 0:02:12.    Training Loss: 0.1112440814380534.\n",
            "  Batch 200  of  7334.    Elapsed: 0:02:45.    Training Loss: 0.09903655190020799.\n",
            "  Batch 240  of  7334.    Elapsed: 0:03:18.    Training Loss: 0.09035455151461065.\n",
            "  Batch 280  of  7334.    Elapsed: 0:03:50.    Training Loss: 0.08383637638097363.\n",
            "  Batch 320  of  7334.    Elapsed: 0:04:23.    Training Loss: 0.07834344859584234.\n",
            "  Batch 360  of  7334.    Elapsed: 0:04:56.    Training Loss: 0.07410561318716241.\n",
            "  Batch 400  of  7334.    Elapsed: 0:05:29.    Training Loss: 0.07080644879490137.\n",
            "  Batch 440  of  7334.    Elapsed: 0:06:02.    Training Loss: 0.06761700986799869.\n",
            "  Batch 480  of  7334.    Elapsed: 0:06:35.    Training Loss: 0.06471940009311462.\n",
            "  Batch 520  of  7334.    Elapsed: 0:07:08.    Training Loss: 0.06259390663606329.\n",
            "  Batch 560  of  7334.    Elapsed: 0:07:41.    Training Loss: 0.06066645766841248.\n",
            "  Batch 600  of  7334.    Elapsed: 0:08:14.    Training Loss: 0.058899542675353585.\n",
            "  Batch 640  of  7334.    Elapsed: 0:08:47.    Training Loss: 0.05734394519386114.\n",
            "  Batch 680  of  7334.    Elapsed: 0:09:20.    Training Loss: 0.055768513728809706.\n",
            "  Batch 720  of  7334.    Elapsed: 0:09:53.    Training Loss: 0.054425745593228686.\n",
            "  Batch 760  of  7334.    Elapsed: 0:10:25.    Training Loss: 0.053099222879513706.\n",
            "  Batch 800  of  7334.    Elapsed: 0:10:58.    Training Loss: 0.051950387401739136.\n",
            "  Batch 840  of  7334.    Elapsed: 0:11:31.    Training Loss: 0.05088303555024876.\n",
            "  Batch 880  of  7334.    Elapsed: 0:12:04.    Training Loss: 0.049817670670613136.\n",
            "  Batch 920  of  7334.    Elapsed: 0:12:37.    Training Loss: 0.04887288324534893.\n",
            "  Batch 960  of  7334.    Elapsed: 0:13:10.    Training Loss: 0.04788006769376807.\n",
            "  Batch 1000  of  7334.    Elapsed: 0:13:43.    Training Loss: 0.047040397546254095.\n",
            "  Batch 1040  of  7334.    Elapsed: 0:14:16.    Training Loss: 0.04633250048903462.\n",
            "  Batch 1080  of  7334.    Elapsed: 0:14:49.    Training Loss: 0.045681535505206775.\n",
            "  Batch 1120  of  7334.    Elapsed: 0:15:22.    Training Loss: 0.04504800040324751.\n",
            "  Batch 1160  of  7334.    Elapsed: 0:15:55.    Training Loss: 0.04434185691884365.\n",
            "  Batch 1200  of  7334.    Elapsed: 0:16:28.    Training Loss: 0.04377913226839155.\n",
            "  Batch 1240  of  7334.    Elapsed: 0:17:00.    Training Loss: 0.04324619154175443.\n",
            "  Batch 1280  of  7334.    Elapsed: 0:17:33.    Training Loss: 0.042758147852873664.\n",
            "  Batch 1320  of  7334.    Elapsed: 0:18:06.    Training Loss: 0.042359190694564446.\n",
            "  Batch 1360  of  7334.    Elapsed: 0:18:39.    Training Loss: 0.0419028489764862.\n",
            "  Batch 1400  of  7334.    Elapsed: 0:19:12.    Training Loss: 0.041524767292264314.\n",
            "  Batch 1440  of  7334.    Elapsed: 0:19:45.    Training Loss: 0.04120607097283937.\n",
            "  Batch 1480  of  7334.    Elapsed: 0:20:18.    Training Loss: 0.04077640307588956.\n",
            "  Batch 1520  of  7334.    Elapsed: 0:20:51.    Training Loss: 0.040417108160909265.\n",
            "  Batch 1560  of  7334.    Elapsed: 0:21:24.    Training Loss: 0.04009191058516407.\n",
            "  Batch 1600  of  7334.    Elapsed: 0:21:57.    Training Loss: 0.03978236972528976.\n",
            "  Batch 1640  of  7334.    Elapsed: 0:22:30.    Training Loss: 0.03940367467258489.\n",
            "  Batch 1680  of  7334.    Elapsed: 0:23:03.    Training Loss: 0.039135339768559096.\n",
            "  Batch 1720  of  7334.    Elapsed: 0:23:36.    Training Loss: 0.038833485631445466.\n",
            "  Batch 1760  of  7334.    Elapsed: 0:24:09.    Training Loss: 0.03852867861384187.\n",
            "  Batch 1800  of  7334.    Elapsed: 0:24:42.    Training Loss: 0.03825725637272828.\n",
            "  Batch 1840  of  7334.    Elapsed: 0:25:15.    Training Loss: 0.03798393484802269.\n",
            "  Batch 1880  of  7334.    Elapsed: 0:25:48.    Training Loss: 0.03774648847781677.\n",
            "  Batch 1920  of  7334.    Elapsed: 0:26:21.    Training Loss: 0.03741720613325015.\n",
            "  Batch 1960  of  7334.    Elapsed: 0:26:54.    Training Loss: 0.03711267017702363.\n",
            "  Batch 2000  of  7334.    Elapsed: 0:27:26.    Training Loss: 0.036880049610044804.\n",
            "  Batch 2040  of  7334.    Elapsed: 0:27:59.    Training Loss: 0.036587115424666916.\n",
            "  Batch 2080  of  7334.    Elapsed: 0:28:32.    Training Loss: 0.036349218206193586.\n",
            "  Batch 2120  of  7334.    Elapsed: 0:29:05.    Training Loss: 0.036170110418373404.\n",
            "  Batch 2160  of  7334.    Elapsed: 0:29:38.    Training Loss: 0.036015687916100166.\n",
            "  Batch 2200  of  7334.    Elapsed: 0:30:11.    Training Loss: 0.03582441980019212.\n",
            "  Batch 2240  of  7334.    Elapsed: 0:30:44.    Training Loss: 0.035586264650087934.\n",
            "  Batch 2280  of  7334.    Elapsed: 0:31:17.    Training Loss: 0.03545664195012171.\n",
            "  Batch 2320  of  7334.    Elapsed: 0:31:50.    Training Loss: 0.0351967910509396.\n",
            "  Batch 2360  of  7334.    Elapsed: 0:32:23.    Training Loss: 0.03502175647733828.\n",
            "  Batch 2400  of  7334.    Elapsed: 0:32:56.    Training Loss: 0.03485547162456593.\n",
            "  Batch 2440  of  7334.    Elapsed: 0:33:29.    Training Loss: 0.03464348431157528.\n",
            "  Batch 2480  of  7334.    Elapsed: 0:34:02.    Training Loss: 0.034514648938972145.\n",
            "  Batch 2520  of  7334.    Elapsed: 0:34:35.    Training Loss: 0.03433857924297511.\n",
            "  Batch 2560  of  7334.    Elapsed: 0:35:08.    Training Loss: 0.034168169511758606.\n",
            "  Batch 2600  of  7334.    Elapsed: 0:35:41.    Training Loss: 0.03405115797041127.\n",
            "  Batch 2640  of  7334.    Elapsed: 0:36:14.    Training Loss: 0.03390303608206468.\n",
            "  Batch 2680  of  7334.    Elapsed: 0:36:47.    Training Loss: 0.03375593754462898.\n",
            "  Batch 2720  of  7334.    Elapsed: 0:37:20.    Training Loss: 0.033636158147676135.\n",
            "  Batch 2760  of  7334.    Elapsed: 0:37:53.    Training Loss: 0.033433922388307426.\n",
            "  Batch 2800  of  7334.    Elapsed: 0:38:26.    Training Loss: 0.03327886068062591.\n",
            "  Batch 2840  of  7334.    Elapsed: 0:38:59.    Training Loss: 0.03316484785107502.\n",
            "  Batch 2880  of  7334.    Elapsed: 0:39:32.    Training Loss: 0.033042454486551125.\n",
            "  Batch 2920  of  7334.    Elapsed: 0:40:05.    Training Loss: 0.03295455475525982.\n",
            "  Batch 2960  of  7334.    Elapsed: 0:40:37.    Training Loss: 0.03283699759033609.\n",
            "  Batch 3000  of  7334.    Elapsed: 0:41:10.    Training Loss: 0.03270328865091627.\n",
            "  Batch 3040  of  7334.    Elapsed: 0:41:43.    Training Loss: 0.03254073092646554.\n",
            "  Batch 3080  of  7334.    Elapsed: 0:42:16.    Training Loss: 0.03240872167289717.\n",
            "  Batch 3120  of  7334.    Elapsed: 0:42:49.    Training Loss: 0.03228227981688598.\n",
            "  Batch 3160  of  7334.    Elapsed: 0:43:22.    Training Loss: 0.03214869053291652.\n",
            "  Batch 3200  of  7334.    Elapsed: 0:43:55.    Training Loss: 0.03210623360559112.\n",
            "  Batch 3240  of  7334.    Elapsed: 0:44:28.    Training Loss: 0.03198717331605745.\n",
            "  Batch 3280  of  7334.    Elapsed: 0:45:01.    Training Loss: 0.03194326258423488.\n",
            "  Batch 3320  of  7334.    Elapsed: 0:45:34.    Training Loss: 0.03186040463722704.\n",
            "  Batch 3360  of  7334.    Elapsed: 0:46:07.    Training Loss: 0.031771373201904464.\n",
            "  Batch 3400  of  7334.    Elapsed: 0:46:40.    Training Loss: 0.03169872130185147.\n",
            "  Batch 3440  of  7334.    Elapsed: 0:47:13.    Training Loss: 0.031634207116169204.\n",
            "  Batch 3480  of  7334.    Elapsed: 0:47:46.    Training Loss: 0.0314976932701719.\n",
            "  Batch 3520  of  7334.    Elapsed: 0:48:19.    Training Loss: 0.031458621814619454.\n",
            "  Batch 3560  of  7334.    Elapsed: 0:48:52.    Training Loss: 0.03136967338904152.\n",
            "  Batch 3600  of  7334.    Elapsed: 0:49:25.    Training Loss: 0.03128545623259722.\n",
            "  Batch 3640  of  7334.    Elapsed: 0:49:58.    Training Loss: 0.031219197850249666.\n",
            "  Batch 3680  of  7334.    Elapsed: 0:50:31.    Training Loss: 0.031121614369761158.\n",
            "  Batch 3720  of  7334.    Elapsed: 0:51:04.    Training Loss: 0.031054110342000802.\n",
            "  Batch 3760  of  7334.    Elapsed: 0:51:37.    Training Loss: 0.030954627941506222.\n",
            "  Batch 3800  of  7334.    Elapsed: 0:52:10.    Training Loss: 0.030860961806641794.\n",
            "  Batch 3840  of  7334.    Elapsed: 0:52:43.    Training Loss: 0.030770386461396508.\n",
            "  Batch 3880  of  7334.    Elapsed: 0:53:16.    Training Loss: 0.030653738052003353.\n",
            "  Batch 3920  of  7334.    Elapsed: 0:53:49.    Training Loss: 0.030592769658435326.\n",
            "  Batch 3960  of  7334.    Elapsed: 0:54:22.    Training Loss: 0.030523029930602685.\n",
            "  Batch 4000  of  7334.    Elapsed: 0:54:55.    Training Loss: 0.0304455172958551.\n",
            "  Batch 4040  of  7334.    Elapsed: 0:55:28.    Training Loss: 0.03037208265067069.\n",
            "  Batch 4080  of  7334.    Elapsed: 0:56:01.    Training Loss: 0.030291523835758734.\n",
            "  Batch 4120  of  7334.    Elapsed: 0:56:33.    Training Loss: 0.030213861505374386.\n",
            "  Batch 4160  of  7334.    Elapsed: 0:57:06.    Training Loss: 0.030113772099251108.\n",
            "  Batch 4200  of  7334.    Elapsed: 0:57:39.    Training Loss: 0.030028370892784248.\n",
            "  Batch 4240  of  7334.    Elapsed: 0:58:12.    Training Loss: 0.029967245824507632.\n",
            "  Batch 4280  of  7334.    Elapsed: 0:58:45.    Training Loss: 0.02992621315044795.\n",
            "  Batch 4320  of  7334.    Elapsed: 0:59:18.    Training Loss: 0.029868457302843498.\n",
            "  Batch 4360  of  7334.    Elapsed: 0:59:51.    Training Loss: 0.029811382452090092.\n",
            "  Batch 4400  of  7334.    Elapsed: 1:00:24.    Training Loss: 0.029759643037104978.\n",
            "  Batch 4440  of  7334.    Elapsed: 1:00:57.    Training Loss: 0.029676591368866162.\n",
            "  Batch 4480  of  7334.    Elapsed: 1:01:30.    Training Loss: 0.02962760627831033.\n",
            "  Batch 4520  of  7334.    Elapsed: 1:02:03.    Training Loss: 0.029528917560448655.\n",
            "  Batch 4560  of  7334.    Elapsed: 1:02:36.    Training Loss: 0.029486316233248402.\n",
            "  Batch 4600  of  7334.    Elapsed: 1:03:09.    Training Loss: 0.029418952297723.\n",
            "  Batch 4640  of  7334.    Elapsed: 1:03:42.    Training Loss: 0.029349207448680758.\n",
            "  Batch 4680  of  7334.    Elapsed: 1:04:15.    Training Loss: 0.02928542971997084.\n",
            "  Batch 4720  of  7334.    Elapsed: 1:04:48.    Training Loss: 0.02922134801915105.\n",
            "  Batch 4760  of  7334.    Elapsed: 1:05:21.    Training Loss: 0.02918815996171124.\n",
            "  Batch 4800  of  7334.    Elapsed: 1:05:54.    Training Loss: 0.029146183205981894.\n",
            "  Batch 4840  of  7334.    Elapsed: 1:06:27.    Training Loss: 0.029106793173661934.\n",
            "  Batch 4880  of  7334.    Elapsed: 1:07:00.    Training Loss: 0.029055452710456505.\n",
            "  Batch 4920  of  7334.    Elapsed: 1:07:33.    Training Loss: 0.028999997812183195.\n",
            "  Batch 4960  of  7334.    Elapsed: 1:08:06.    Training Loss: 0.028923552767505058.\n",
            "  Batch 5000  of  7334.    Elapsed: 1:08:39.    Training Loss: 0.028846773683838547.\n",
            "  Batch 5040  of  7334.    Elapsed: 1:09:12.    Training Loss: 0.02876132175063951.\n",
            "  Batch 5080  of  7334.    Elapsed: 1:09:45.    Training Loss: 0.02872929439703956.\n",
            "  Batch 5120  of  7334.    Elapsed: 1:10:18.    Training Loss: 0.02868154417392361.\n",
            "  Batch 5160  of  7334.    Elapsed: 1:10:51.    Training Loss: 0.02862258656356527.\n",
            "  Batch 5200  of  7334.    Elapsed: 1:11:24.    Training Loss: 0.028564397883064186.\n",
            "  Batch 5240  of  7334.    Elapsed: 1:11:57.    Training Loss: 0.02852893568546945.\n",
            "  Batch 5280  of  7334.    Elapsed: 1:12:30.    Training Loss: 0.028499073206242457.\n",
            "  Batch 5320  of  7334.    Elapsed: 1:13:03.    Training Loss: 0.028484519104879435.\n",
            "  Batch 5360  of  7334.    Elapsed: 1:13:36.    Training Loss: 0.028435768929845305.\n",
            "  Batch 5400  of  7334.    Elapsed: 1:14:09.    Training Loss: 0.028379086844485115.\n",
            "  Batch 5440  of  7334.    Elapsed: 1:14:42.    Training Loss: 0.028312308889443933.\n",
            "  Batch 5480  of  7334.    Elapsed: 1:15:15.    Training Loss: 0.028263541849935087.\n",
            "  Batch 5520  of  7334.    Elapsed: 1:15:47.    Training Loss: 0.028200961115425856.\n",
            "  Batch 5560  of  7334.    Elapsed: 1:16:20.    Training Loss: 0.028159509751135015.\n",
            "  Batch 5600  of  7334.    Elapsed: 1:16:53.    Training Loss: 0.02809463371946809.\n",
            "  Batch 5640  of  7334.    Elapsed: 1:17:26.    Training Loss: 0.028055265378405123.\n",
            "  Batch 5680  of  7334.    Elapsed: 1:17:59.    Training Loss: 0.027985641487191994.\n",
            "  Batch 5720  of  7334.    Elapsed: 1:18:32.    Training Loss: 0.027932561196100252.\n",
            "  Batch 5760  of  7334.    Elapsed: 1:19:05.    Training Loss: 0.02790629793210731.\n",
            "  Batch 5800  of  7334.    Elapsed: 1:19:38.    Training Loss: 0.027841234873048962.\n",
            "  Batch 5840  of  7334.    Elapsed: 1:20:11.    Training Loss: 0.02779717168560226.\n",
            "  Batch 5880  of  7334.    Elapsed: 1:20:44.    Training Loss: 0.027759288820171996.\n",
            "  Batch 5920  of  7334.    Elapsed: 1:21:17.    Training Loss: 0.027719671853717317.\n",
            "  Batch 5960  of  7334.    Elapsed: 1:21:50.    Training Loss: 0.027677054210697244.\n",
            "  Batch 6000  of  7334.    Elapsed: 1:22:23.    Training Loss: 0.027652840880521883.\n",
            "  Batch 6040  of  7334.    Elapsed: 1:22:56.    Training Loss: 0.027635037656935143.\n",
            "  Batch 6080  of  7334.    Elapsed: 1:23:29.    Training Loss: 0.02759621413815215.\n",
            "  Batch 6120  of  7334.    Elapsed: 1:24:02.    Training Loss: 0.027552912986739935.\n",
            "  Batch 6160  of  7334.    Elapsed: 1:24:35.    Training Loss: 0.027510405561959297.\n",
            "  Batch 6200  of  7334.    Elapsed: 1:25:08.    Training Loss: 0.027456339258745674.\n",
            "  Batch 6240  of  7334.    Elapsed: 1:25:41.    Training Loss: 0.027441272124624213.\n",
            "  Batch 6280  of  7334.    Elapsed: 1:26:14.    Training Loss: 0.027395986435804397.\n",
            "  Batch 6320  of  7334.    Elapsed: 1:26:47.    Training Loss: 0.02734574375193731.\n",
            "  Batch 6360  of  7334.    Elapsed: 1:27:20.    Training Loss: 0.027320814561010952.\n",
            "  Batch 6400  of  7334.    Elapsed: 1:27:53.    Training Loss: 0.027291662925636048.\n",
            "  Batch 6440  of  7334.    Elapsed: 1:28:26.    Training Loss: 0.027272853193882715.\n",
            "  Batch 6480  of  7334.    Elapsed: 1:28:59.    Training Loss: 0.02722543941036062.\n",
            "  Batch 6520  of  7334.    Elapsed: 1:29:32.    Training Loss: 0.027189896390144856.\n",
            "  Batch 6560  of  7334.    Elapsed: 1:30:05.    Training Loss: 0.027169886275291124.\n",
            "  Batch 6600  of  7334.    Elapsed: 1:30:38.    Training Loss: 0.027135049941751994.\n",
            "  Batch 6640  of  7334.    Elapsed: 1:31:11.    Training Loss: 0.027111812977959032.\n",
            "  Batch 6680  of  7334.    Elapsed: 1:31:44.    Training Loss: 0.027082636168653224.\n",
            "  Batch 6720  of  7334.    Elapsed: 1:32:17.    Training Loss: 0.027048179428675212.\n",
            "  Batch 6760  of  7334.    Elapsed: 1:32:50.    Training Loss: 0.02700870683907184.\n",
            "  Batch 6800  of  7334.    Elapsed: 1:33:23.    Training Loss: 0.0269637012765195.\n",
            "  Batch 6840  of  7334.    Elapsed: 1:33:56.    Training Loss: 0.02693773800376476.\n",
            "  Batch 6880  of  7334.    Elapsed: 1:34:29.    Training Loss: 0.0268975714638526.\n",
            "  Batch 6920  of  7334.    Elapsed: 1:35:02.    Training Loss: 0.02685836786976235.\n",
            "  Batch 6960  of  7334.    Elapsed: 1:35:35.    Training Loss: 0.02682424189068575.\n",
            "  Batch 7000  of  7334.    Elapsed: 1:36:08.    Training Loss: 0.026795501734362914.\n",
            "  Batch 7040  of  7334.    Elapsed: 1:36:41.    Training Loss: 0.0267657274568509.\n",
            "  Batch 7080  of  7334.    Elapsed: 1:37:14.    Training Loss: 0.026742392212861496.\n",
            "  Batch 7120  of  7334.    Elapsed: 1:37:47.    Training Loss: 0.026718127381238365.\n",
            "  Batch 7160  of  7334.    Elapsed: 1:38:19.    Training Loss: 0.026699747417386174.\n",
            "  Batch 7200  of  7334.    Elapsed: 1:38:52.    Training Loss: 0.026651495339109613.\n",
            "  Batch 7240  of  7334.    Elapsed: 1:39:25.    Training Loss: 0.026644366065095543.\n",
            "  Batch 7280  of  7334.    Elapsed: 1:39:58.    Training Loss: 0.026603502255082796.\n",
            "  Batch 7320  of  7334.    Elapsed: 1:40:31.    Training Loss: 0.0265681271914894.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epoch took: 1:40:45\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.14\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:06:57\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "  Batch 40  of  7334.    Elapsed: 0:00:33.    Training Loss: 0.018833817751146852.\n",
            "  Batch 80  of  7334.    Elapsed: 0:01:06.    Training Loss: 0.017949176637921484.\n",
            "  Batch 120  of  7334.    Elapsed: 0:01:39.    Training Loss: 0.017565351070758576.\n",
            "  Batch 160  of  7334.    Elapsed: 0:02:12.    Training Loss: 0.016759076522430406.\n",
            "  Batch 200  of  7334.    Elapsed: 0:02:45.    Training Loss: 0.016479339005891235.\n",
            "  Batch 240  of  7334.    Elapsed: 0:03:18.    Training Loss: 0.01627830689928184.\n",
            "  Batch 280  of  7334.    Elapsed: 0:03:51.    Training Loss: 0.016344558090038066.\n",
            "  Batch 320  of  7334.    Elapsed: 0:04:24.    Training Loss: 0.016410175121563952.\n",
            "  Batch 360  of  7334.    Elapsed: 0:04:57.    Training Loss: 0.01625505212513316.\n",
            "  Batch 400  of  7334.    Elapsed: 0:05:30.    Training Loss: 0.016223709639161824.\n",
            "  Batch 440  of  7334.    Elapsed: 0:06:03.    Training Loss: 0.016220739640464835.\n",
            "  Batch 480  of  7334.    Elapsed: 0:06:36.    Training Loss: 0.016209675968275404.\n",
            "  Batch 520  of  7334.    Elapsed: 0:07:09.    Training Loss: 0.01619613795326306.\n",
            "  Batch 560  of  7334.    Elapsed: 0:07:42.    Training Loss: 0.0162620734248776.\n",
            "  Batch 600  of  7334.    Elapsed: 0:08:15.    Training Loss: 0.016176646453483653.\n",
            "  Batch 640  of  7334.    Elapsed: 0:08:48.    Training Loss: 0.016241624499525643.\n",
            "  Batch 680  of  7334.    Elapsed: 0:09:21.    Training Loss: 0.016150069428498254.\n",
            "  Batch 720  of  7334.    Elapsed: 0:09:54.    Training Loss: 0.016142582132144728.\n",
            "  Batch 760  of  7334.    Elapsed: 0:10:27.    Training Loss: 0.01625870561447779.\n",
            "  Batch 800  of  7334.    Elapsed: 0:11:00.    Training Loss: 0.016398703181184828.\n",
            "  Batch 840  of  7334.    Elapsed: 0:11:33.    Training Loss: 0.016379942926799968.\n",
            "  Batch 880  of  7334.    Elapsed: 0:12:06.    Training Loss: 0.016335917058908803.\n",
            "  Batch 920  of  7334.    Elapsed: 0:12:39.    Training Loss: 0.016375681823726906.\n",
            "  Batch 960  of  7334.    Elapsed: 0:13:12.    Training Loss: 0.016379308969771956.\n",
            "  Batch 1000  of  7334.    Elapsed: 0:13:45.    Training Loss: 0.016345364415086806.\n",
            "  Batch 1040  of  7334.    Elapsed: 0:14:18.    Training Loss: 0.01634455688494759.\n",
            "  Batch 1080  of  7334.    Elapsed: 0:14:51.    Training Loss: 0.01637229741404385.\n",
            "  Batch 1120  of  7334.    Elapsed: 0:15:24.    Training Loss: 0.01639277724607382.\n",
            "  Batch 1160  of  7334.    Elapsed: 0:15:57.    Training Loss: 0.016365309595531816.\n",
            "  Batch 1200  of  7334.    Elapsed: 0:16:30.    Training Loss: 0.01627724989084527.\n",
            "  Batch 1240  of  7334.    Elapsed: 0:17:03.    Training Loss: 0.016281768738577562.\n",
            "  Batch 1280  of  7334.    Elapsed: 0:17:36.    Training Loss: 0.016265097215728018.\n",
            "  Batch 1320  of  7334.    Elapsed: 0:18:09.    Training Loss: 0.01625746747754006.\n",
            "  Batch 1360  of  7334.    Elapsed: 0:18:42.    Training Loss: 0.016287586985238117.\n",
            "  Batch 1400  of  7334.    Elapsed: 0:19:15.    Training Loss: 0.01622637699724042.\n",
            "  Batch 1440  of  7334.    Elapsed: 0:19:48.    Training Loss: 0.016210682639050195.\n",
            "  Batch 1480  of  7334.    Elapsed: 0:20:21.    Training Loss: 0.016218638153450968.\n",
            "  Batch 1520  of  7334.    Elapsed: 0:20:54.    Training Loss: 0.01630161023763082.\n",
            "  Batch 1560  of  7334.    Elapsed: 0:21:27.    Training Loss: 0.01627987008377647.\n",
            "  Batch 1600  of  7334.    Elapsed: 0:22:00.    Training Loss: 0.016258513962238794.\n",
            "  Batch 1640  of  7334.    Elapsed: 0:22:33.    Training Loss: 0.01632410668606143.\n",
            "  Batch 1680  of  7334.    Elapsed: 0:23:06.    Training Loss: 0.01630827079380175.\n",
            "  Batch 1720  of  7334.    Elapsed: 0:23:39.    Training Loss: 0.0162536162592005.\n",
            "  Batch 1760  of  7334.    Elapsed: 0:24:12.    Training Loss: 0.01632210763173961.\n",
            "  Batch 1800  of  7334.    Elapsed: 0:24:45.    Training Loss: 0.01635649064180648.\n",
            "  Batch 1840  of  7334.    Elapsed: 0:25:18.    Training Loss: 0.0163442396053933.\n",
            "  Batch 1880  of  7334.    Elapsed: 0:25:51.    Training Loss: 0.016281445095181823.\n",
            "  Batch 1920  of  7334.    Elapsed: 0:26:24.    Training Loss: 0.016309022090839183.\n",
            "  Batch 1960  of  7334.    Elapsed: 0:26:57.    Training Loss: 0.016311501616692856.\n",
            "  Batch 2000  of  7334.    Elapsed: 0:27:30.    Training Loss: 0.016276479178923182.\n",
            "  Batch 2040  of  7334.    Elapsed: 0:28:03.    Training Loss: 0.016232050718013744.\n",
            "  Batch 2080  of  7334.    Elapsed: 0:28:36.    Training Loss: 0.016238834994258537.\n",
            "  Batch 2120  of  7334.    Elapsed: 0:29:09.    Training Loss: 0.016230044283745988.\n",
            "  Batch 2160  of  7334.    Elapsed: 0:29:42.    Training Loss: 0.016220976414020965.\n",
            "  Batch 2200  of  7334.    Elapsed: 0:30:15.    Training Loss: 0.016207540237387134.\n",
            "  Batch 2240  of  7334.    Elapsed: 0:30:48.    Training Loss: 0.016197258379751084.\n",
            "  Batch 2280  of  7334.    Elapsed: 0:31:21.    Training Loss: 0.01622799676414089.\n",
            "  Batch 2320  of  7334.    Elapsed: 0:31:54.    Training Loss: 0.0162579828552131.\n",
            "  Batch 2360  of  7334.    Elapsed: 0:32:28.    Training Loss: 0.016243379694603037.\n",
            "  Batch 2400  of  7334.    Elapsed: 0:33:01.    Training Loss: 0.016255797440826426.\n",
            "  Batch 2440  of  7334.    Elapsed: 0:33:34.    Training Loss: 0.016252722384572243.\n",
            "  Batch 2480  of  7334.    Elapsed: 0:34:07.    Training Loss: 0.016308623275272698.\n",
            "  Batch 2520  of  7334.    Elapsed: 0:34:40.    Training Loss: 0.016328696860092886.\n",
            "  Batch 2560  of  7334.    Elapsed: 0:35:13.    Training Loss: 0.016333029759880446.\n",
            "  Batch 2600  of  7334.    Elapsed: 0:35:46.    Training Loss: 0.016343932871241123.\n",
            "  Batch 2640  of  7334.    Elapsed: 0:36:19.    Training Loss: 0.016333411347163332.\n",
            "  Batch 2680  of  7334.    Elapsed: 0:36:52.    Training Loss: 0.01630194998631226.\n",
            "  Batch 2720  of  7334.    Elapsed: 0:37:25.    Training Loss: 0.01631194381402833.\n",
            "  Batch 2760  of  7334.    Elapsed: 0:37:59.    Training Loss: 0.016345869997293566.\n",
            "  Batch 2800  of  7334.    Elapsed: 0:38:32.    Training Loss: 0.016334210697761073.\n",
            "  Batch 2840  of  7334.    Elapsed: 0:39:05.    Training Loss: 0.016319903368982945.\n",
            "  Batch 2880  of  7334.    Elapsed: 0:39:38.    Training Loss: 0.01632506942033716.\n",
            "  Batch 2920  of  7334.    Elapsed: 0:40:11.    Training Loss: 0.01632790312997053.\n",
            "  Batch 2960  of  7334.    Elapsed: 0:40:44.    Training Loss: 0.016339368412170457.\n",
            "  Batch 3000  of  7334.    Elapsed: 0:41:17.    Training Loss: 0.016310378249113758.\n",
            "  Batch 3040  of  7334.    Elapsed: 0:41:50.    Training Loss: 0.016324562063642876.\n",
            "  Batch 3080  of  7334.    Elapsed: 0:42:23.    Training Loss: 0.01632286250340305.\n",
            "  Batch 3120  of  7334.    Elapsed: 0:42:56.    Training Loss: 0.016330534557047752.\n",
            "  Batch 3160  of  7334.    Elapsed: 0:43:30.    Training Loss: 0.016302440582356074.\n",
            "  Batch 3200  of  7334.    Elapsed: 0:44:03.    Training Loss: 0.016269388889850234.\n",
            "  Batch 3240  of  7334.    Elapsed: 0:44:36.    Training Loss: 0.016240504909131422.\n",
            "  Batch 3280  of  7334.    Elapsed: 0:45:09.    Training Loss: 0.016221855448703734.\n",
            "  Batch 3320  of  7334.    Elapsed: 0:45:42.    Training Loss: 0.01623256931338089.\n",
            "  Batch 3360  of  7334.    Elapsed: 0:46:15.    Training Loss: 0.01620936325593253.\n",
            "  Batch 3400  of  7334.    Elapsed: 0:46:48.    Training Loss: 0.016201605953358334.\n",
            "  Batch 3440  of  7334.    Elapsed: 0:47:21.    Training Loss: 0.01619865701298316.\n",
            "  Batch 3480  of  7334.    Elapsed: 0:47:54.    Training Loss: 0.01620027458980337.\n",
            "  Batch 3520  of  7334.    Elapsed: 0:48:27.    Training Loss: 0.016173446459552824.\n",
            "  Batch 3560  of  7334.    Elapsed: 0:49:00.    Training Loss: 0.016176334110329326.\n",
            "  Batch 3600  of  7334.    Elapsed: 0:49:33.    Training Loss: 0.016194863950626717.\n",
            "  Batch 3640  of  7334.    Elapsed: 0:50:06.    Training Loss: 0.01619548195266871.\n",
            "  Batch 3680  of  7334.    Elapsed: 0:50:39.    Training Loss: 0.0162086152705698.\n",
            "  Batch 3720  of  7334.    Elapsed: 0:51:12.    Training Loss: 0.016228569764143195.\n",
            "  Batch 3760  of  7334.    Elapsed: 0:51:45.    Training Loss: 0.01625561129309217.\n",
            "  Batch 3800  of  7334.    Elapsed: 0:52:18.    Training Loss: 0.016247954871505498.\n",
            "  Batch 3840  of  7334.    Elapsed: 0:52:51.    Training Loss: 0.01623420454513204.\n",
            "  Batch 3880  of  7334.    Elapsed: 0:53:24.    Training Loss: 0.016251298905345466.\n",
            "  Batch 3920  of  7334.    Elapsed: 0:53:57.    Training Loss: 0.016254377816221677.\n",
            "  Batch 3960  of  7334.    Elapsed: 0:54:30.    Training Loss: 0.016252006445199984.\n",
            "  Batch 4000  of  7334.    Elapsed: 0:55:03.    Training Loss: 0.01625642777659232.\n",
            "  Batch 4040  of  7334.    Elapsed: 0:55:36.    Training Loss: 0.016231324312468473.\n",
            "  Batch 4080  of  7334.    Elapsed: 0:56:09.    Training Loss: 0.01623819008687575.\n",
            "  Batch 4120  of  7334.    Elapsed: 0:56:42.    Training Loss: 0.01624027759733031.\n",
            "  Batch 4160  of  7334.    Elapsed: 0:57:15.    Training Loss: 0.016245553952299256.\n",
            "  Batch 4200  of  7334.    Elapsed: 0:57:48.    Training Loss: 0.016225910069188103.\n",
            "  Batch 4240  of  7334.    Elapsed: 0:58:21.    Training Loss: 0.016201861970783386.\n",
            "  Batch 4280  of  7334.    Elapsed: 0:58:54.    Training Loss: 0.016202530952684025.\n",
            "  Batch 4320  of  7334.    Elapsed: 0:59:27.    Training Loss: 0.01618826066152434.\n",
            "  Batch 4360  of  7334.    Elapsed: 1:00:00.    Training Loss: 0.016178028658352828.\n",
            "  Batch 4400  of  7334.    Elapsed: 1:00:33.    Training Loss: 0.016177423900120298.\n",
            "  Batch 4440  of  7334.    Elapsed: 1:01:06.    Training Loss: 0.01617676313653974.\n",
            "  Batch 4480  of  7334.    Elapsed: 1:01:39.    Training Loss: 0.01616207090306229.\n",
            "  Batch 4520  of  7334.    Elapsed: 1:02:12.    Training Loss: 0.016171586633643417.\n",
            "  Batch 4560  of  7334.    Elapsed: 1:02:45.    Training Loss: 0.016151202043820697.\n",
            "  Batch 4600  of  7334.    Elapsed: 1:03:18.    Training Loss: 0.016150954525269892.\n",
            "  Batch 4640  of  7334.    Elapsed: 1:03:51.    Training Loss: 0.016133184569430185.\n",
            "  Batch 4680  of  7334.    Elapsed: 1:04:24.    Training Loss: 0.016152681685629913.\n",
            "  Batch 4720  of  7334.    Elapsed: 1:04:57.    Training Loss: 0.016155310440512563.\n",
            "  Batch 4760  of  7334.    Elapsed: 1:05:30.    Training Loss: 0.016171261629856683.\n",
            "  Batch 4800  of  7334.    Elapsed: 1:06:03.    Training Loss: 0.016168890479602852.\n",
            "  Batch 4840  of  7334.    Elapsed: 1:06:36.    Training Loss: 0.016173367762711083.\n",
            "  Batch 4880  of  7334.    Elapsed: 1:07:09.    Training Loss: 0.016168137026672084.\n",
            "  Batch 4920  of  7334.    Elapsed: 1:07:42.    Training Loss: 0.016162970111273774.\n",
            "  Batch 4960  of  7334.    Elapsed: 1:08:15.    Training Loss: 0.01617183740543682.\n",
            "  Batch 5000  of  7334.    Elapsed: 1:08:48.    Training Loss: 0.01616445416850038.\n",
            "  Batch 5040  of  7334.    Elapsed: 1:09:21.    Training Loss: 0.016142323729905508.\n",
            "  Batch 5080  of  7334.    Elapsed: 1:09:54.    Training Loss: 0.01614371768916649.\n",
            "  Batch 5120  of  7334.    Elapsed: 1:10:27.    Training Loss: 0.016142630981221373.\n",
            "  Batch 5160  of  7334.    Elapsed: 1:11:00.    Training Loss: 0.016136621754903477.\n",
            "  Batch 5200  of  7334.    Elapsed: 1:11:33.    Training Loss: 0.016129504760879522.\n",
            "  Batch 5240  of  7334.    Elapsed: 1:12:06.    Training Loss: 0.01613038337290934.\n",
            "  Batch 5280  of  7334.    Elapsed: 1:12:39.    Training Loss: 0.016123522351060245.\n",
            "  Batch 5320  of  7334.    Elapsed: 1:13:12.    Training Loss: 0.016137668479687388.\n",
            "  Batch 5360  of  7334.    Elapsed: 1:13:45.    Training Loss: 0.0161343426329393.\n",
            "  Batch 5400  of  7334.    Elapsed: 1:14:18.    Training Loss: 0.016151753195294143.\n",
            "  Batch 5440  of  7334.    Elapsed: 1:14:51.    Training Loss: 0.016144434811062907.\n",
            "  Batch 5480  of  7334.    Elapsed: 1:15:24.    Training Loss: 0.016133519123694144.\n",
            "  Batch 5520  of  7334.    Elapsed: 1:15:57.    Training Loss: 0.016132532426981133.\n",
            "  Batch 5560  of  7334.    Elapsed: 1:16:30.    Training Loss: 0.016148695039936416.\n",
            "  Batch 5600  of  7334.    Elapsed: 1:17:03.    Training Loss: 0.01613989052084175.\n",
            "  Batch 5640  of  7334.    Elapsed: 1:17:35.    Training Loss: 0.016117614731134794.\n",
            "  Batch 5680  of  7334.    Elapsed: 1:18:08.    Training Loss: 0.01611718511914762.\n",
            "  Batch 5720  of  7334.    Elapsed: 1:18:41.    Training Loss: 0.016114748950756215.\n",
            "  Batch 5760  of  7334.    Elapsed: 1:19:14.    Training Loss: 0.016103138923911804.\n",
            "  Batch 5800  of  7334.    Elapsed: 1:19:47.    Training Loss: 0.016094530094133946.\n",
            "  Batch 5840  of  7334.    Elapsed: 1:20:20.    Training Loss: 0.016090993409496348.\n",
            "  Batch 5880  of  7334.    Elapsed: 1:20:53.    Training Loss: 0.016085588831421253.\n",
            "  Batch 5920  of  7334.    Elapsed: 1:21:26.    Training Loss: 0.01609572765603819.\n",
            "  Batch 5960  of  7334.    Elapsed: 1:21:59.    Training Loss: 0.016080862809958612.\n",
            "  Batch 6000  of  7334.    Elapsed: 1:22:32.    Training Loss: 0.016068975688540377.\n",
            "  Batch 6040  of  7334.    Elapsed: 1:23:05.    Training Loss: 0.016055725346163643.\n",
            "  Batch 6080  of  7334.    Elapsed: 1:23:38.    Training Loss: 0.01606485741967366.\n",
            "  Batch 6120  of  7334.    Elapsed: 1:24:11.    Training Loss: 0.016066387138638366.\n",
            "  Batch 6160  of  7334.    Elapsed: 1:24:44.    Training Loss: 0.016069532214858958.\n",
            "  Batch 6200  of  7334.    Elapsed: 1:25:17.    Training Loss: 0.016066518240841106.\n",
            "  Batch 6240  of  7334.    Elapsed: 1:25:50.    Training Loss: 0.016064368701989178.\n",
            "  Batch 6280  of  7334.    Elapsed: 1:26:23.    Training Loss: 0.01608161989537922.\n",
            "  Batch 6320  of  7334.    Elapsed: 1:26:56.    Training Loss: 0.016072429519380985.\n",
            "  Batch 6360  of  7334.    Elapsed: 1:27:29.    Training Loss: 0.016063640178832862.\n",
            "  Batch 6400  of  7334.    Elapsed: 1:28:02.    Training Loss: 0.016055297214297753.\n",
            "  Batch 6440  of  7334.    Elapsed: 1:28:35.    Training Loss: 0.016070865848360538.\n",
            "  Batch 6480  of  7334.    Elapsed: 1:29:08.    Training Loss: 0.016072011407411567.\n",
            "  Batch 6520  of  7334.    Elapsed: 1:29:41.    Training Loss: 0.0160823995096429.\n",
            "  Batch 6560  of  7334.    Elapsed: 1:30:14.    Training Loss: 0.01607644874244082.\n",
            "  Batch 6600  of  7334.    Elapsed: 1:30:47.    Training Loss: 0.016084875456643093.\n",
            "  Batch 6640  of  7334.    Elapsed: 1:31:20.    Training Loss: 0.016080997336595543.\n",
            "  Batch 6680  of  7334.    Elapsed: 1:31:53.    Training Loss: 0.016083183806301735.\n",
            "  Batch 6720  of  7334.    Elapsed: 1:32:26.    Training Loss: 0.01607225742554874.\n",
            "  Batch 6760  of  7334.    Elapsed: 1:32:59.    Training Loss: 0.01606838808352949.\n",
            "  Batch 6800  of  7334.    Elapsed: 1:33:32.    Training Loss: 0.01608299906779875.\n",
            "  Batch 6840  of  7334.    Elapsed: 1:34:05.    Training Loss: 0.016077501153537992.\n",
            "  Batch 6880  of  7334.    Elapsed: 1:34:38.    Training Loss: 0.01607222952893502.\n",
            "  Batch 6920  of  7334.    Elapsed: 1:35:11.    Training Loss: 0.01608396058429754.\n",
            "  Batch 6960  of  7334.    Elapsed: 1:35:44.    Training Loss: 0.016087143204640598.\n",
            "  Batch 7000  of  7334.    Elapsed: 1:36:17.    Training Loss: 0.016094090357189998.\n",
            "  Batch 7040  of  7334.    Elapsed: 1:36:50.    Training Loss: 0.016112031079782436.\n",
            "  Batch 7080  of  7334.    Elapsed: 1:37:23.    Training Loss: 0.01610497605390347.\n",
            "  Batch 7120  of  7334.    Elapsed: 1:37:56.    Training Loss: 0.01609016324248259.\n",
            "  Batch 7160  of  7334.    Elapsed: 1:38:29.    Training Loss: 0.01607860588922566.\n",
            "  Batch 7200  of  7334.    Elapsed: 1:39:02.    Training Loss: 0.016073212196157934.\n",
            "  Batch 7240  of  7334.    Elapsed: 1:39:35.    Training Loss: 0.01605592844390326.\n",
            "  Batch 7280  of  7334.    Elapsed: 1:40:08.    Training Loss: 0.016066500780608884.\n",
            "  Batch 7320  of  7334.    Elapsed: 1:40:41.    Training Loss: 0.01606378520802656.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 1:40:54\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.14\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:06:57\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "  Batch 40  of  7334.    Elapsed: 0:00:33.    Training Loss: 0.012529135541990399.\n",
            "  Batch 80  of  7334.    Elapsed: 0:01:06.    Training Loss: 0.012583674406050705.\n",
            "  Batch 120  of  7334.    Elapsed: 0:01:39.    Training Loss: 0.012514976276240002.\n",
            "  Batch 160  of  7334.    Elapsed: 0:02:12.    Training Loss: 0.012844454290461726.\n",
            "  Batch 200  of  7334.    Elapsed: 0:02:45.    Training Loss: 0.01282311946619302.\n",
            "  Batch 240  of  7334.    Elapsed: 0:03:18.    Training Loss: 0.012330409844677585.\n",
            "  Batch 280  of  7334.    Elapsed: 0:03:51.    Training Loss: 0.012323246749084709.\n",
            "  Batch 320  of  7334.    Elapsed: 0:04:24.    Training Loss: 0.012067850365565392.\n",
            "  Batch 360  of  7334.    Elapsed: 0:04:57.    Training Loss: 0.011994834799164284.\n",
            "  Batch 400  of  7334.    Elapsed: 0:05:30.    Training Loss: 0.011917993069509976.\n",
            "  Batch 440  of  7334.    Elapsed: 0:06:03.    Training Loss: 0.01190301177610474.\n",
            "  Batch 480  of  7334.    Elapsed: 0:06:36.    Training Loss: 0.011959783573790144.\n",
            "  Batch 520  of  7334.    Elapsed: 0:07:09.    Training Loss: 0.011936000794118556.\n",
            "  Batch 560  of  7334.    Elapsed: 0:07:42.    Training Loss: 0.0120435863621034.\n",
            "  Batch 600  of  7334.    Elapsed: 0:08:15.    Training Loss: 0.01198099014077646.\n",
            "  Batch 640  of  7334.    Elapsed: 0:08:48.    Training Loss: 0.012079748855830985.\n",
            "  Batch 680  of  7334.    Elapsed: 0:09:21.    Training Loss: 0.011999959016205085.\n",
            "  Batch 720  of  7334.    Elapsed: 0:09:54.    Training Loss: 0.011951065905870766.\n",
            "  Batch 760  of  7334.    Elapsed: 0:10:27.    Training Loss: 0.011877090651480677.\n",
            "  Batch 800  of  7334.    Elapsed: 0:11:00.    Training Loss: 0.011993918227090035.\n",
            "  Batch 840  of  7334.    Elapsed: 0:11:33.    Training Loss: 0.011997459690541118.\n",
            "  Batch 880  of  7334.    Elapsed: 0:12:06.    Training Loss: 0.011979773224977014.\n",
            "  Batch 920  of  7334.    Elapsed: 0:12:39.    Training Loss: 0.011967811157228425.\n",
            "  Batch 960  of  7334.    Elapsed: 0:13:12.    Training Loss: 0.012007819582019389.\n",
            "  Batch 1000  of  7334.    Elapsed: 0:13:45.    Training Loss: 0.012030098672257737.\n",
            "  Batch 1040  of  7334.    Elapsed: 0:14:18.    Training Loss: 0.012001560572221374.\n",
            "  Batch 1080  of  7334.    Elapsed: 0:14:51.    Training Loss: 0.012014182655063148.\n",
            "  Batch 1120  of  7334.    Elapsed: 0:15:24.    Training Loss: 0.011997112040782148.\n",
            "  Batch 1160  of  7334.    Elapsed: 0:15:57.    Training Loss: 0.011964212822655602.\n",
            "  Batch 1200  of  7334.    Elapsed: 0:16:30.    Training Loss: 0.011962381315145952.\n",
            "  Batch 1240  of  7334.    Elapsed: 0:17:03.    Training Loss: 0.011927588942137758.\n",
            "  Batch 1280  of  7334.    Elapsed: 0:17:36.    Training Loss: 0.011946626465760345.\n",
            "  Batch 1320  of  7334.    Elapsed: 0:18:09.    Training Loss: 0.01195689073894314.\n",
            "  Batch 1360  of  7334.    Elapsed: 0:18:42.    Training Loss: 0.011928620371070472.\n",
            "  Batch 1400  of  7334.    Elapsed: 0:19:15.    Training Loss: 0.011934022016191323.\n",
            "  Batch 1440  of  7334.    Elapsed: 0:19:48.    Training Loss: 0.01190164157241169.\n",
            "  Batch 1480  of  7334.    Elapsed: 0:20:21.    Training Loss: 0.011913037061301136.\n",
            "  Batch 1520  of  7334.    Elapsed: 0:20:54.    Training Loss: 0.011901089605740517.\n",
            "  Batch 1560  of  7334.    Elapsed: 0:21:27.    Training Loss: 0.01191916100633068.\n",
            "  Batch 1600  of  7334.    Elapsed: 0:22:00.    Training Loss: 0.011950416000327096.\n",
            "  Batch 1640  of  7334.    Elapsed: 0:22:33.    Training Loss: 0.011918485880170653.\n",
            "  Batch 1680  of  7334.    Elapsed: 0:23:06.    Training Loss: 0.011914710430262078.\n",
            "  Batch 1720  of  7334.    Elapsed: 0:23:39.    Training Loss: 0.011930723306127326.\n",
            "  Batch 1760  of  7334.    Elapsed: 0:24:12.    Training Loss: 0.011945058338989673.\n",
            "  Batch 1800  of  7334.    Elapsed: 0:24:45.    Training Loss: 0.011949345507503798.\n",
            "  Batch 1840  of  7334.    Elapsed: 0:25:18.    Training Loss: 0.01197328072107073.\n",
            "  Batch 1880  of  7334.    Elapsed: 0:25:51.    Training Loss: 0.011993430320797686.\n",
            "  Batch 1920  of  7334.    Elapsed: 0:26:24.    Training Loss: 0.012030565927125281.\n",
            "  Batch 1960  of  7334.    Elapsed: 0:26:57.    Training Loss: 0.0120258804491474.\n",
            "  Batch 2000  of  7334.    Elapsed: 0:27:30.    Training Loss: 0.01202023573499173.\n",
            "  Batch 2040  of  7334.    Elapsed: 0:28:03.    Training Loss: 0.0120549883631825.\n",
            "  Batch 2080  of  7334.    Elapsed: 0:28:36.    Training Loss: 0.012038431964957944.\n",
            "  Batch 2120  of  7334.    Elapsed: 0:29:09.    Training Loss: 0.012041978315529325.\n",
            "  Batch 2160  of  7334.    Elapsed: 0:29:42.    Training Loss: 0.012021512520732358.\n",
            "  Batch 2200  of  7334.    Elapsed: 0:30:15.    Training Loss: 0.012009729025885462.\n",
            "  Batch 2240  of  7334.    Elapsed: 0:30:48.    Training Loss: 0.01200656324373475.\n",
            "  Batch 2280  of  7334.    Elapsed: 0:31:21.    Training Loss: 0.012013281653573933.\n",
            "  Batch 2320  of  7334.    Elapsed: 0:31:54.    Training Loss: 0.012024564795890534.\n",
            "  Batch 2360  of  7334.    Elapsed: 0:32:27.    Training Loss: 0.01200783564235573.\n",
            "  Batch 2400  of  7334.    Elapsed: 0:33:00.    Training Loss: 0.011995928737645349.\n",
            "  Batch 2440  of  7334.    Elapsed: 0:33:33.    Training Loss: 0.012020476093156965.\n",
            "  Batch 2480  of  7334.    Elapsed: 0:34:06.    Training Loss: 0.012020536338827843.\n",
            "  Batch 2520  of  7334.    Elapsed: 0:34:39.    Training Loss: 0.012044628724522357.\n",
            "  Batch 2560  of  7334.    Elapsed: 0:35:12.    Training Loss: 0.012047992289262765.\n",
            "  Batch 2600  of  7334.    Elapsed: 0:35:45.    Training Loss: 0.012040480883577122.\n",
            "  Batch 2640  of  7334.    Elapsed: 0:36:18.    Training Loss: 0.012039745140778409.\n",
            "  Batch 2680  of  7334.    Elapsed: 0:36:51.    Training Loss: 0.012025403023398579.\n",
            "  Batch 2720  of  7334.    Elapsed: 0:37:24.    Training Loss: 0.012009373400531546.\n",
            "  Batch 2760  of  7334.    Elapsed: 0:37:57.    Training Loss: 0.011969804926184883.\n",
            "  Batch 2800  of  7334.    Elapsed: 0:38:30.    Training Loss: 0.01198869766991785.\n",
            "  Batch 2840  of  7334.    Elapsed: 0:39:03.    Training Loss: 0.01198709321964178.\n",
            "  Batch 2880  of  7334.    Elapsed: 0:39:36.    Training Loss: 0.01198421354096758.\n",
            "  Batch 2920  of  7334.    Elapsed: 0:40:09.    Training Loss: 0.011996558508660313.\n",
            "  Batch 2960  of  7334.    Elapsed: 0:40:42.    Training Loss: 0.01201577681703556.\n",
            "  Batch 3000  of  7334.    Elapsed: 0:41:15.    Training Loss: 0.012000073621748016.\n",
            "  Batch 3040  of  7334.    Elapsed: 0:41:48.    Training Loss: 0.012013713447423038.\n",
            "  Batch 3080  of  7334.    Elapsed: 0:42:21.    Training Loss: 0.012006094570456122.\n",
            "  Batch 3120  of  7334.    Elapsed: 0:42:54.    Training Loss: 0.011996157344382925.\n",
            "  Batch 3160  of  7334.    Elapsed: 0:43:27.    Training Loss: 0.01201618117835856.\n",
            "  Batch 3200  of  7334.    Elapsed: 0:44:00.    Training Loss: 0.012017313731848844.\n",
            "  Batch 3240  of  7334.    Elapsed: 0:44:33.    Training Loss: 0.012028600144225897.\n",
            "  Batch 3280  of  7334.    Elapsed: 0:45:06.    Training Loss: 0.012040727301259388.\n",
            "  Batch 3320  of  7334.    Elapsed: 0:45:39.    Training Loss: 0.012045046548760239.\n",
            "  Batch 3360  of  7334.    Elapsed: 0:46:12.    Training Loss: 0.01205869336727552.\n",
            "  Batch 3400  of  7334.    Elapsed: 0:46:45.    Training Loss: 0.012053910907946856.\n",
            "  Batch 3440  of  7334.    Elapsed: 0:47:18.    Training Loss: 0.012043141959665538.\n",
            "  Batch 3480  of  7334.    Elapsed: 0:47:51.    Training Loss: 0.012050178094737596.\n",
            "  Batch 3520  of  7334.    Elapsed: 0:48:24.    Training Loss: 0.01204826906416036.\n",
            "  Batch 3560  of  7334.    Elapsed: 0:48:57.    Training Loss: 0.012035005169546524.\n",
            "  Batch 3600  of  7334.    Elapsed: 0:49:30.    Training Loss: 0.01203115576716502.\n",
            "  Batch 3640  of  7334.    Elapsed: 0:50:03.    Training Loss: 0.012030589927543097.\n",
            "  Batch 3680  of  7334.    Elapsed: 0:50:36.    Training Loss: 0.012026106622310496.\n",
            "  Batch 3720  of  7334.    Elapsed: 0:51:09.    Training Loss: 0.012034982851623828.\n",
            "  Batch 3760  of  7334.    Elapsed: 0:51:42.    Training Loss: 0.012034847568460502.\n",
            "  Batch 3800  of  7334.    Elapsed: 0:52:15.    Training Loss: 0.012035834178340768.\n",
            "  Batch 3840  of  7334.    Elapsed: 0:52:48.    Training Loss: 0.012040710974239725.\n",
            "  Batch 3880  of  7334.    Elapsed: 0:53:21.    Training Loss: 0.012023453802871278.\n",
            "  Batch 3920  of  7334.    Elapsed: 0:53:54.    Training Loss: 0.01200538735049159.\n",
            "  Batch 3960  of  7334.    Elapsed: 0:54:27.    Training Loss: 0.012030093876510915.\n",
            "  Batch 4000  of  7334.    Elapsed: 0:54:59.    Training Loss: 0.012023646009329241.\n",
            "  Batch 4040  of  7334.    Elapsed: 0:55:32.    Training Loss: 0.012033404595400714.\n",
            "  Batch 4080  of  7334.    Elapsed: 0:56:05.    Training Loss: 0.01205309312453941.\n",
            "  Batch 4120  of  7334.    Elapsed: 0:56:38.    Training Loss: 0.01203851712685648.\n",
            "  Batch 4160  of  7334.    Elapsed: 0:57:11.    Training Loss: 0.012042124856704434.\n",
            "  Batch 4200  of  7334.    Elapsed: 0:57:44.    Training Loss: 0.012053582422778986.\n",
            "  Batch 4240  of  7334.    Elapsed: 0:58:17.    Training Loss: 0.012090867251500418.\n",
            "  Batch 4280  of  7334.    Elapsed: 0:58:50.    Training Loss: 0.012098399754646277.\n",
            "  Batch 4320  of  7334.    Elapsed: 0:59:23.    Training Loss: 0.01210389113300523.\n",
            "  Batch 4360  of  7334.    Elapsed: 0:59:56.    Training Loss: 0.01211325405128172.\n",
            "  Batch 4400  of  7334.    Elapsed: 1:00:29.    Training Loss: 0.012108584765440107.\n",
            "  Batch 4440  of  7334.    Elapsed: 1:01:02.    Training Loss: 0.01210036229500589.\n",
            "  Batch 4480  of  7334.    Elapsed: 1:01:35.    Training Loss: 0.01209909116738085.\n",
            "  Batch 4520  of  7334.    Elapsed: 1:02:08.    Training Loss: 0.012109637204135265.\n",
            "  Batch 4560  of  7334.    Elapsed: 1:02:41.    Training Loss: 0.012122630147649416.\n",
            "  Batch 4600  of  7334.    Elapsed: 1:03:14.    Training Loss: 0.01211296902944172.\n",
            "  Batch 4640  of  7334.    Elapsed: 1:03:47.    Training Loss: 0.012120008324915221.\n",
            "  Batch 4680  of  7334.    Elapsed: 1:04:20.    Training Loss: 0.01212143461034896.\n",
            "  Batch 4720  of  7334.    Elapsed: 1:04:53.    Training Loss: 0.012141594380609912.\n",
            "  Batch 4760  of  7334.    Elapsed: 1:05:26.    Training Loss: 0.012135216543947917.\n",
            "  Batch 4800  of  7334.    Elapsed: 1:05:59.    Training Loss: 0.012137462810399787.\n",
            "  Batch 4840  of  7334.    Elapsed: 1:06:32.    Training Loss: 0.012134917464957781.\n",
            "  Batch 4880  of  7334.    Elapsed: 1:07:05.    Training Loss: 0.012139973692122663.\n",
            "  Batch 4920  of  7334.    Elapsed: 1:07:38.    Training Loss: 0.012131118511296507.\n",
            "  Batch 4960  of  7334.    Elapsed: 1:08:11.    Training Loss: 0.012135640979226259.\n",
            "  Batch 5000  of  7334.    Elapsed: 1:08:44.    Training Loss: 0.012151281551085413.\n",
            "  Batch 5040  of  7334.    Elapsed: 1:09:17.    Training Loss: 0.012160132934398476.\n",
            "  Batch 5080  of  7334.    Elapsed: 1:09:50.    Training Loss: 0.01215591429609908.\n",
            "  Batch 5120  of  7334.    Elapsed: 1:10:23.    Training Loss: 0.012161538121927152.\n",
            "  Batch 5160  of  7334.    Elapsed: 1:10:56.    Training Loss: 0.012154059522954905.\n",
            "  Batch 5200  of  7334.    Elapsed: 1:11:29.    Training Loss: 0.012150876984859888.\n",
            "  Batch 5240  of  7334.    Elapsed: 1:12:02.    Training Loss: 0.012150881344982146.\n",
            "  Batch 5280  of  7334.    Elapsed: 1:12:35.    Training Loss: 0.012155293961228436.\n",
            "  Batch 5320  of  7334.    Elapsed: 1:13:08.    Training Loss: 0.012153231872847878.\n",
            "  Batch 5360  of  7334.    Elapsed: 1:13:41.    Training Loss: 0.012167558506732361.\n",
            "  Batch 5400  of  7334.    Elapsed: 1:14:14.    Training Loss: 0.012166245791509196.\n",
            "  Batch 5440  of  7334.    Elapsed: 1:14:47.    Training Loss: 0.01216862873698119.\n",
            "  Batch 5480  of  7334.    Elapsed: 1:15:20.    Training Loss: 0.012165022252066346.\n",
            "  Batch 5520  of  7334.    Elapsed: 1:15:53.    Training Loss: 0.012156079708939364.\n",
            "  Batch 5560  of  7334.    Elapsed: 1:16:26.    Training Loss: 0.012156492680405005.\n",
            "  Batch 5600  of  7334.    Elapsed: 1:16:59.    Training Loss: 0.012152500464040454.\n",
            "  Batch 5640  of  7334.    Elapsed: 1:17:32.    Training Loss: 0.012148648646539606.\n",
            "  Batch 5680  of  7334.    Elapsed: 1:18:05.    Training Loss: 0.012151793704218965.\n",
            "  Batch 5720  of  7334.    Elapsed: 1:18:38.    Training Loss: 0.012140427999502908.\n",
            "  Batch 5760  of  7334.    Elapsed: 1:19:11.    Training Loss: 0.012147091884617111.\n",
            "  Batch 5800  of  7334.    Elapsed: 1:19:44.    Training Loss: 0.012145566165744295.\n",
            "  Batch 5840  of  7334.    Elapsed: 1:20:17.    Training Loss: 0.012147256443380659.\n",
            "  Batch 5880  of  7334.    Elapsed: 1:20:50.    Training Loss: 0.012159761382531387.\n",
            "  Batch 5920  of  7334.    Elapsed: 1:21:23.    Training Loss: 0.012144334026576158.\n",
            "  Batch 5960  of  7334.    Elapsed: 1:21:56.    Training Loss: 0.012140943360829026.\n",
            "  Batch 6000  of  7334.    Elapsed: 1:22:29.    Training Loss: 0.012139719417667947.\n",
            "  Batch 6040  of  7334.    Elapsed: 1:23:02.    Training Loss: 0.012130049520152134.\n",
            "  Batch 6080  of  7334.    Elapsed: 1:23:35.    Training Loss: 0.012124353727076117.\n",
            "  Batch 6120  of  7334.    Elapsed: 1:24:08.    Training Loss: 0.012130230749703128.\n",
            "  Batch 6160  of  7334.    Elapsed: 1:24:41.    Training Loss: 0.0121343806063584.\n",
            "  Batch 6200  of  7334.    Elapsed: 1:25:14.    Training Loss: 0.01213672046748651.\n",
            "  Batch 6240  of  7334.    Elapsed: 1:25:47.    Training Loss: 0.012132061271329757.\n",
            "  Batch 6280  of  7334.    Elapsed: 1:26:20.    Training Loss: 0.012128952867314398.\n",
            "  Batch 6320  of  7334.    Elapsed: 1:26:53.    Training Loss: 0.012121173096607039.\n",
            "  Batch 6360  of  7334.    Elapsed: 1:27:26.    Training Loss: 0.012127558480100355.\n",
            "  Batch 6400  of  7334.    Elapsed: 1:27:59.    Training Loss: 0.012136919837612368.\n",
            "  Batch 6440  of  7334.    Elapsed: 1:28:32.    Training Loss: 0.012144791670411142.\n",
            "  Batch 6480  of  7334.    Elapsed: 1:29:05.    Training Loss: 0.012145847553224877.\n",
            "  Batch 6520  of  7334.    Elapsed: 1:29:38.    Training Loss: 0.012149706912695494.\n",
            "  Batch 6560  of  7334.    Elapsed: 1:30:11.    Training Loss: 0.01215046046978919.\n",
            "  Batch 6600  of  7334.    Elapsed: 1:30:44.    Training Loss: 0.012156007709898844.\n",
            "  Batch 6640  of  7334.    Elapsed: 1:31:17.    Training Loss: 0.012146374945394157.\n",
            "  Batch 6680  of  7334.    Elapsed: 1:31:49.    Training Loss: 0.012144785606745674.\n",
            "  Batch 6720  of  7334.    Elapsed: 1:32:22.    Training Loss: 0.012149778689282747.\n",
            "  Batch 6760  of  7334.    Elapsed: 1:32:55.    Training Loss: 0.012147282681100005.\n",
            "  Batch 6800  of  7334.    Elapsed: 1:33:28.    Training Loss: 0.012152075164143324.\n",
            "  Batch 6840  of  7334.    Elapsed: 1:34:01.    Training Loss: 0.012150380301101361.\n",
            "  Batch 6880  of  7334.    Elapsed: 1:34:34.    Training Loss: 0.012149156406616554.\n",
            "  Batch 6920  of  7334.    Elapsed: 1:35:07.    Training Loss: 0.012140922563694246.\n",
            "  Batch 6960  of  7334.    Elapsed: 1:35:40.    Training Loss: 0.012150044504408564.\n",
            "  Batch 7000  of  7334.    Elapsed: 1:36:13.    Training Loss: 0.012152990763341741.\n",
            "  Batch 7040  of  7334.    Elapsed: 1:36:46.    Training Loss: 0.012155860686537132.\n",
            "  Batch 7080  of  7334.    Elapsed: 1:37:19.    Training Loss: 0.012157829050079914.\n",
            "  Batch 7120  of  7334.    Elapsed: 1:37:52.    Training Loss: 0.01216166255913225.\n",
            "  Batch 7160  of  7334.    Elapsed: 1:38:25.    Training Loss: 0.012162352543436094.\n",
            "  Batch 7200  of  7334.    Elapsed: 1:38:58.    Training Loss: 0.012166236848020668.\n",
            "  Batch 7240  of  7334.    Elapsed: 1:39:31.    Training Loss: 0.01216070923091746.\n",
            "  Batch 7280  of  7334.    Elapsed: 1:40:04.    Training Loss: 0.012148694785479405.\n",
            "  Batch 7320  of  7334.    Elapsed: 1:40:37.    Training Loss: 0.012154248879256766.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 1:40:51\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.14\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:06:57\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "  Batch 40  of  7334.    Elapsed: 0:00:33.    Training Loss: 0.008864458976313471.\n",
            "  Batch 80  of  7334.    Elapsed: 0:01:06.    Training Loss: 0.009194982692133636.\n",
            "  Batch 120  of  7334.    Elapsed: 0:01:39.    Training Loss: 0.009580671471000338.\n",
            "  Batch 160  of  7334.    Elapsed: 0:02:12.    Training Loss: 0.009959541671560147.\n",
            "  Batch 200  of  7334.    Elapsed: 0:02:45.    Training Loss: 0.009798818472772837.\n",
            "  Batch 240  of  7334.    Elapsed: 0:03:18.    Training Loss: 0.00978094591991976.\n",
            "  Batch 280  of  7334.    Elapsed: 0:03:51.    Training Loss: 0.009724425088747272.\n",
            "  Batch 320  of  7334.    Elapsed: 0:04:24.    Training Loss: 0.00975121267256327.\n",
            "  Batch 360  of  7334.    Elapsed: 0:04:57.    Training Loss: 0.009667675139563571.\n",
            "  Batch 400  of  7334.    Elapsed: 0:05:30.    Training Loss: 0.00965133382298518.\n",
            "  Batch 440  of  7334.    Elapsed: 0:06:03.    Training Loss: 0.009548040913333269.\n",
            "  Batch 480  of  7334.    Elapsed: 0:06:36.    Training Loss: 0.00956525970977964.\n",
            "  Batch 520  of  7334.    Elapsed: 0:07:09.    Training Loss: 0.009574733861686231.\n",
            "  Batch 560  of  7334.    Elapsed: 0:07:42.    Training Loss: 0.009544923173130623.\n",
            "  Batch 600  of  7334.    Elapsed: 0:08:15.    Training Loss: 0.009640088129478197.\n",
            "  Batch 640  of  7334.    Elapsed: 0:08:48.    Training Loss: 0.009700178198909271.\n",
            "  Batch 680  of  7334.    Elapsed: 0:09:21.    Training Loss: 0.009674043550416279.\n",
            "  Batch 720  of  7334.    Elapsed: 0:09:54.    Training Loss: 0.009716806053054623.\n",
            "  Batch 760  of  7334.    Elapsed: 0:10:27.    Training Loss: 0.00969926597930393.\n",
            "  Batch 800  of  7334.    Elapsed: 0:11:00.    Training Loss: 0.00973427208897192.\n",
            "  Batch 840  of  7334.    Elapsed: 0:11:33.    Training Loss: 0.00972817884647243.\n",
            "  Batch 880  of  7334.    Elapsed: 0:12:06.    Training Loss: 0.009697335097536614.\n",
            "  Batch 920  of  7334.    Elapsed: 0:12:39.    Training Loss: 0.00977098219800214.\n",
            "  Batch 960  of  7334.    Elapsed: 0:13:12.    Training Loss: 0.009753156647881648.\n",
            "  Batch 1000  of  7334.    Elapsed: 0:13:45.    Training Loss: 0.00976637690141797.\n",
            "  Batch 1040  of  7334.    Elapsed: 0:14:18.    Training Loss: 0.009812305297684641.\n",
            "  Batch 1080  of  7334.    Elapsed: 0:14:51.    Training Loss: 0.009774961627166097.\n",
            "  Batch 1120  of  7334.    Elapsed: 0:15:24.    Training Loss: 0.00973628516741363.\n",
            "  Batch 1160  of  7334.    Elapsed: 0:15:57.    Training Loss: 0.009775629952742622.\n",
            "  Batch 1200  of  7334.    Elapsed: 0:16:30.    Training Loss: 0.009778669316049976.\n",
            "  Batch 1240  of  7334.    Elapsed: 0:17:03.    Training Loss: 0.00972552522209533.\n",
            "  Batch 1280  of  7334.    Elapsed: 0:17:36.    Training Loss: 0.00971214600103849.\n",
            "  Batch 1320  of  7334.    Elapsed: 0:18:09.    Training Loss: 0.009714339190395549.\n",
            "  Batch 1360  of  7334.    Elapsed: 0:18:42.    Training Loss: 0.009704265589243732.\n",
            "  Batch 1400  of  7334.    Elapsed: 0:19:15.    Training Loss: 0.009741161638937358.\n",
            "  Batch 1440  of  7334.    Elapsed: 0:19:48.    Training Loss: 0.009700840409883919.\n",
            "  Batch 1480  of  7334.    Elapsed: 0:20:21.    Training Loss: 0.009688847300886.\n",
            "  Batch 1520  of  7334.    Elapsed: 0:20:54.    Training Loss: 0.009691098623443395.\n",
            "  Batch 1560  of  7334.    Elapsed: 0:21:27.    Training Loss: 0.009702877523765589.\n",
            "  Batch 1600  of  7334.    Elapsed: 0:22:00.    Training Loss: 0.009704430029960348.\n",
            "  Batch 1640  of  7334.    Elapsed: 0:22:33.    Training Loss: 0.009709657627589456.\n",
            "  Batch 1680  of  7334.    Elapsed: 0:23:06.    Training Loss: 0.009696521973126523.\n",
            "  Batch 1720  of  7334.    Elapsed: 0:23:39.    Training Loss: 0.009663542920891412.\n",
            "  Batch 1760  of  7334.    Elapsed: 0:24:12.    Training Loss: 0.009648976786279077.\n",
            "  Batch 1800  of  7334.    Elapsed: 0:24:45.    Training Loss: 0.009670628161143719.\n",
            "  Batch 1840  of  7334.    Elapsed: 0:25:18.    Training Loss: 0.009655909816881277.\n",
            "  Batch 1880  of  7334.    Elapsed: 0:25:51.    Training Loss: 0.009650547948958194.\n",
            "  Batch 1920  of  7334.    Elapsed: 0:26:24.    Training Loss: 0.009635618052683034.\n",
            "  Batch 1960  of  7334.    Elapsed: 0:26:57.    Training Loss: 0.009624222725301943.\n",
            "  Batch 2000  of  7334.    Elapsed: 0:27:30.    Training Loss: 0.00963321676349733.\n",
            "  Batch 2040  of  7334.    Elapsed: 0:28:03.    Training Loss: 0.009625801163401419.\n",
            "  Batch 2080  of  7334.    Elapsed: 0:28:36.    Training Loss: 0.009613862244497376.\n",
            "  Batch 2120  of  7334.    Elapsed: 0:29:09.    Training Loss: 0.009597576878424559.\n",
            "  Batch 2160  of  7334.    Elapsed: 0:29:42.    Training Loss: 0.009584933600530752.\n",
            "  Batch 2200  of  7334.    Elapsed: 0:30:15.    Training Loss: 0.009603770087494261.\n",
            "  Batch 2240  of  7334.    Elapsed: 0:30:48.    Training Loss: 0.009601133117082229.\n",
            "  Batch 2280  of  7334.    Elapsed: 0:31:21.    Training Loss: 0.009630587377806046.\n",
            "  Batch 2320  of  7334.    Elapsed: 0:31:54.    Training Loss: 0.009630599534460183.\n",
            "  Batch 2360  of  7334.    Elapsed: 0:32:27.    Training Loss: 0.009618378128615697.\n",
            "  Batch 2400  of  7334.    Elapsed: 0:33:00.    Training Loss: 0.009603595623145035.\n",
            "  Batch 2440  of  7334.    Elapsed: 0:33:33.    Training Loss: 0.009599377565776746.\n",
            "  Batch 2480  of  7334.    Elapsed: 0:34:06.    Training Loss: 0.009600514555800585.\n",
            "  Batch 2520  of  7334.    Elapsed: 0:34:39.    Training Loss: 0.009600917749210364.\n",
            "  Batch 2560  of  7334.    Elapsed: 0:35:12.    Training Loss: 0.009592377563694753.\n",
            "  Batch 2600  of  7334.    Elapsed: 0:35:45.    Training Loss: 0.009594074426523339.\n",
            "  Batch 2640  of  7334.    Elapsed: 0:36:18.    Training Loss: 0.00960017294203157.\n",
            "  Batch 2680  of  7334.    Elapsed: 0:36:51.    Training Loss: 0.00958859543020684.\n",
            "  Batch 2720  of  7334.    Elapsed: 0:37:24.    Training Loss: 0.009585291080293245.\n",
            "  Batch 2760  of  7334.    Elapsed: 0:37:57.    Training Loss: 0.009604693698507829.\n",
            "  Batch 2800  of  7334.    Elapsed: 0:38:30.    Training Loss: 0.009608616334984877.\n",
            "  Batch 2840  of  7334.    Elapsed: 0:39:03.    Training Loss: 0.009606149467528129.\n",
            "  Batch 2880  of  7334.    Elapsed: 0:39:36.    Training Loss: 0.009611844881470056.\n",
            "  Batch 2920  of  7334.    Elapsed: 0:40:09.    Training Loss: 0.009598319218350472.\n",
            "  Batch 2960  of  7334.    Elapsed: 0:40:42.    Training Loss: 0.00960242675650374.\n",
            "  Batch 3000  of  7334.    Elapsed: 0:41:15.    Training Loss: 0.009608163652398314.\n",
            "  Batch 3040  of  7334.    Elapsed: 0:41:48.    Training Loss: 0.009606461169957918.\n",
            "  Batch 3080  of  7334.    Elapsed: 0:42:21.    Training Loss: 0.00962421637884184.\n",
            "  Batch 3120  of  7334.    Elapsed: 0:42:54.    Training Loss: 0.009636346179878531.\n",
            "  Batch 3160  of  7334.    Elapsed: 0:43:27.    Training Loss: 0.00963005650555715.\n",
            "  Batch 3200  of  7334.    Elapsed: 0:44:00.    Training Loss: 0.009623269731528127.\n",
            "  Batch 3240  of  7334.    Elapsed: 0:44:33.    Training Loss: 0.009615300158412414.\n",
            "  Batch 3280  of  7334.    Elapsed: 0:45:06.    Training Loss: 0.00961542621740458.\n",
            "  Batch 3320  of  7334.    Elapsed: 0:45:39.    Training Loss: 0.009604202572001055.\n",
            "  Batch 3360  of  7334.    Elapsed: 0:46:12.    Training Loss: 0.009612039554312581.\n",
            "  Batch 3400  of  7334.    Elapsed: 0:46:45.    Training Loss: 0.009617915563696228.\n",
            "  Batch 3440  of  7334.    Elapsed: 0:47:18.    Training Loss: 0.009614987472657028.\n",
            "  Batch 3480  of  7334.    Elapsed: 0:47:51.    Training Loss: 0.009605656126340123.\n",
            "  Batch 3520  of  7334.    Elapsed: 0:48:24.    Training Loss: 0.009604105079051805.\n",
            "  Batch 3560  of  7334.    Elapsed: 0:48:57.    Training Loss: 0.009609348954321565.\n",
            "  Batch 3600  of  7334.    Elapsed: 0:49:30.    Training Loss: 0.009607382523180504.\n",
            "  Batch 3640  of  7334.    Elapsed: 0:50:03.    Training Loss: 0.009596802633457848.\n",
            "  Batch 3680  of  7334.    Elapsed: 0:50:36.    Training Loss: 0.009603083345649318.\n",
            "  Batch 3720  of  7334.    Elapsed: 0:51:09.    Training Loss: 0.009593855718373552.\n",
            "  Batch 3760  of  7334.    Elapsed: 0:51:42.    Training Loss: 0.009590485938477944.\n",
            "  Batch 3800  of  7334.    Elapsed: 0:52:15.    Training Loss: 0.009574427199243616.\n",
            "  Batch 3840  of  7334.    Elapsed: 0:52:48.    Training Loss: 0.009572996524548216.\n",
            "  Batch 3880  of  7334.    Elapsed: 0:53:21.    Training Loss: 0.009570291427326552.\n",
            "  Batch 3920  of  7334.    Elapsed: 0:53:54.    Training Loss: 0.00957707535684565.\n",
            "  Batch 3960  of  7334.    Elapsed: 0:54:27.    Training Loss: 0.009576390207759246.\n",
            "  Batch 4000  of  7334.    Elapsed: 0:55:00.    Training Loss: 0.00958840917161433.\n",
            "  Batch 4040  of  7334.    Elapsed: 0:55:33.    Training Loss: 0.009587401422149833.\n",
            "  Batch 4080  of  7334.    Elapsed: 0:56:06.    Training Loss: 0.00958277450097775.\n",
            "  Batch 4120  of  7334.    Elapsed: 0:56:39.    Training Loss: 0.009565888665355425.\n",
            "  Batch 4160  of  7334.    Elapsed: 0:57:12.    Training Loss: 0.009563961047640008.\n",
            "  Batch 4200  of  7334.    Elapsed: 0:57:45.    Training Loss: 0.009561326992171373.\n",
            "  Batch 4240  of  7334.    Elapsed: 0:58:18.    Training Loss: 0.009562264372158647.\n",
            "  Batch 4280  of  7334.    Elapsed: 0:58:51.    Training Loss: 0.00956688576068394.\n",
            "  Batch 4320  of  7334.    Elapsed: 0:59:24.    Training Loss: 0.009560733542457456.\n",
            "  Batch 4360  of  7334.    Elapsed: 0:59:57.    Training Loss: 0.009562392229264508.\n",
            "  Batch 4400  of  7334.    Elapsed: 1:00:30.    Training Loss: 0.009556855976777363.\n",
            "  Batch 4440  of  7334.    Elapsed: 1:01:03.    Training Loss: 0.009576882635424677.\n",
            "  Batch 4480  of  7334.    Elapsed: 1:01:36.    Training Loss: 0.009576155484501215.\n",
            "  Batch 4520  of  7334.    Elapsed: 1:02:09.    Training Loss: 0.009582213888617554.\n",
            "  Batch 4560  of  7334.    Elapsed: 1:02:42.    Training Loss: 0.009578370236563945.\n",
            "  Batch 4600  of  7334.    Elapsed: 1:03:15.    Training Loss: 0.00958304529718589.\n",
            "  Batch 4640  of  7334.    Elapsed: 1:03:48.    Training Loss: 0.009591612983158797.\n",
            "  Batch 4680  of  7334.    Elapsed: 1:04:21.    Training Loss: 0.009587253012737204.\n",
            "  Batch 4720  of  7334.    Elapsed: 1:04:54.    Training Loss: 0.00958165648160009.\n",
            "  Batch 4760  of  7334.    Elapsed: 1:05:27.    Training Loss: 0.009587771198766094.\n",
            "  Batch 4800  of  7334.    Elapsed: 1:06:00.    Training Loss: 0.009600663270854662.\n",
            "  Batch 4840  of  7334.    Elapsed: 1:06:33.    Training Loss: 0.009600706759975907.\n",
            "  Batch 4880  of  7334.    Elapsed: 1:07:06.    Training Loss: 0.009611846567832934.\n",
            "  Batch 4920  of  7334.    Elapsed: 1:07:39.    Training Loss: 0.00961265184599963.\n",
            "  Batch 4960  of  7334.    Elapsed: 1:08:12.    Training Loss: 0.009614160476649564.\n",
            "  Batch 5000  of  7334.    Elapsed: 1:08:45.    Training Loss: 0.009607534251385368.\n",
            "  Batch 5040  of  7334.    Elapsed: 1:09:18.    Training Loss: 0.009607392496827597.\n",
            "  Batch 5080  of  7334.    Elapsed: 1:09:51.    Training Loss: 0.009609555776160409.\n",
            "  Batch 5120  of  7334.    Elapsed: 1:10:24.    Training Loss: 0.009607845915229517.\n",
            "  Batch 5160  of  7334.    Elapsed: 1:10:57.    Training Loss: 0.00962117267012246.\n",
            "  Batch 5200  of  7334.    Elapsed: 1:11:30.    Training Loss: 0.009622388089572689.\n",
            "  Batch 5240  of  7334.    Elapsed: 1:12:03.    Training Loss: 0.009616383050594174.\n",
            "  Batch 5280  of  7334.    Elapsed: 1:12:36.    Training Loss: 0.00961693354062542.\n",
            "  Batch 5320  of  7334.    Elapsed: 1:13:09.    Training Loss: 0.009619082409351946.\n",
            "  Batch 5360  of  7334.    Elapsed: 1:13:42.    Training Loss: 0.009620718794258888.\n",
            "  Batch 5400  of  7334.    Elapsed: 1:14:15.    Training Loss: 0.00961193475848564.\n",
            "  Batch 5440  of  7334.    Elapsed: 1:14:48.    Training Loss: 0.00960376498859499.\n",
            "  Batch 5480  of  7334.    Elapsed: 1:15:21.    Training Loss: 0.009613334899215897.\n",
            "  Batch 5520  of  7334.    Elapsed: 1:15:54.    Training Loss: 0.009615006555754192.\n",
            "  Batch 5560  of  7334.    Elapsed: 1:16:27.    Training Loss: 0.009624534712060817.\n",
            "  Batch 5600  of  7334.    Elapsed: 1:17:00.    Training Loss: 0.009611769494118303.\n",
            "  Batch 5640  of  7334.    Elapsed: 1:17:33.    Training Loss: 0.009616843412022588.\n",
            "  Batch 5680  of  7334.    Elapsed: 1:18:07.    Training Loss: 0.009616094387077372.\n",
            "  Batch 5720  of  7334.    Elapsed: 1:18:40.    Training Loss: 0.0096095507432889.\n",
            "  Batch 5760  of  7334.    Elapsed: 1:19:13.    Training Loss: 0.009609187452103167.\n",
            "  Batch 5800  of  7334.    Elapsed: 1:19:46.    Training Loss: 0.009614797380335372.\n",
            "  Batch 5840  of  7334.    Elapsed: 1:20:19.    Training Loss: 0.00961407419263819.\n",
            "  Batch 5880  of  7334.    Elapsed: 1:20:52.    Training Loss: 0.009606256422849664.\n",
            "  Batch 5920  of  7334.    Elapsed: 1:21:25.    Training Loss: 0.00961012295911378.\n",
            "  Batch 5960  of  7334.    Elapsed: 1:21:58.    Training Loss: 0.009628214694922102.\n",
            "  Batch 6000  of  7334.    Elapsed: 1:22:31.    Training Loss: 0.009632580335096766.\n",
            "  Batch 6040  of  7334.    Elapsed: 1:23:04.    Training Loss: 0.00962951171384594.\n",
            "  Batch 6080  of  7334.    Elapsed: 1:23:37.    Training Loss: 0.009629346594968075.\n",
            "  Batch 6120  of  7334.    Elapsed: 1:24:10.    Training Loss: 0.009626188621022342.\n",
            "  Batch 6160  of  7334.    Elapsed: 1:24:43.    Training Loss: 0.009619727090050998.\n",
            "  Batch 6200  of  7334.    Elapsed: 1:25:16.    Training Loss: 0.009621531436174748.\n",
            "  Batch 6240  of  7334.    Elapsed: 1:25:49.    Training Loss: 0.00961640729868892.\n",
            "  Batch 6280  of  7334.    Elapsed: 1:26:22.    Training Loss: 0.009614058401417817.\n",
            "  Batch 6320  of  7334.    Elapsed: 1:26:55.    Training Loss: 0.00961413705055425.\n",
            "  Batch 6360  of  7334.    Elapsed: 1:27:28.    Training Loss: 0.009612752738812904.\n",
            "  Batch 6400  of  7334.    Elapsed: 1:28:01.    Training Loss: 0.009608131070599484.\n",
            "  Batch 6440  of  7334.    Elapsed: 1:28:34.    Training Loss: 0.009615999010358272.\n",
            "  Batch 6480  of  7334.    Elapsed: 1:29:07.    Training Loss: 0.00961158429883294.\n",
            "  Batch 6520  of  7334.    Elapsed: 1:29:40.    Training Loss: 0.009622375457690445.\n",
            "  Batch 6560  of  7334.    Elapsed: 1:30:13.    Training Loss: 0.009623939105594906.\n",
            "  Batch 6600  of  7334.    Elapsed: 1:30:46.    Training Loss: 0.009621245948435513.\n",
            "  Batch 6640  of  7334.    Elapsed: 1:31:19.    Training Loss: 0.009622196997908583.\n",
            "  Batch 6680  of  7334.    Elapsed: 1:31:52.    Training Loss: 0.00962978235263277.\n",
            "  Batch 6720  of  7334.    Elapsed: 1:32:25.    Training Loss: 0.00964052483420043.\n",
            "  Batch 6760  of  7334.    Elapsed: 1:32:58.    Training Loss: 0.009639219699438506.\n",
            "  Batch 6800  of  7334.    Elapsed: 1:33:31.    Training Loss: 0.009646469278069322.\n",
            "  Batch 6840  of  7334.    Elapsed: 1:34:04.    Training Loss: 0.009645701224755016.\n",
            "  Batch 6880  of  7334.    Elapsed: 1:34:37.    Training Loss: 0.009654780364017339.\n",
            "  Batch 6920  of  7334.    Elapsed: 1:35:10.    Training Loss: 0.00966222266719752.\n",
            "  Batch 6960  of  7334.    Elapsed: 1:35:43.    Training Loss: 0.009659593652106885.\n",
            "  Batch 7000  of  7334.    Elapsed: 1:36:16.    Training Loss: 0.009655696677243603.\n",
            "  Batch 7040  of  7334.    Elapsed: 1:36:49.    Training Loss: 0.009655387423911387.\n",
            "  Batch 7080  of  7334.    Elapsed: 1:37:22.    Training Loss: 0.009654953047214865.\n",
            "  Batch 7120  of  7334.    Elapsed: 1:37:55.    Training Loss: 0.009659158903320602.\n",
            "  Batch 7160  of  7334.    Elapsed: 1:38:28.    Training Loss: 0.009669995404631627.\n",
            "  Batch 7200  of  7334.    Elapsed: 1:39:01.    Training Loss: 0.009676641620284903.\n",
            "  Batch 7240  of  7334.    Elapsed: 1:39:34.    Training Loss: 0.00968230562459855.\n",
            "  Batch 7280  of  7334.    Elapsed: 1:40:07.    Training Loss: 0.009682892068627592.\n",
            "  Batch 7320  of  7334.    Elapsed: 1:40:41.    Training Loss: 0.009682155109810277.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epoch took: 1:40:54\n",
            "\n",
            "Running Validation...\n",
            "  RMSE: 0.14\n",
            "  Validation Loss: 0.02\n",
            "  Validation took: 0:06:57\n",
            "\n",
            "Training complete!\n",
            "Total training took 7:11:17 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# STILL TO DO: FIGURE OUT HOW TO USE PRETRAINED FOR IMDB DATA? MAYBE UNNECESSARY\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "training_stats = []\n",
        "total_t0=time.time()\n",
        "\n",
        "for epoch in range(4):\n",
        "    print(\"\")\n",
        "    print(f'======== Epoch {epoch+1} / {4} ========')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "      # Progress update every 40 batches.\n",
        "      if step % 40 == 0 and not step == 0:\n",
        "        # Calculate elapsed time in minutes.\n",
        "        elapsed = format_time(time.time()-t0)\n",
        "\n",
        "        # Report progress.\n",
        "        print(f'  Batch {step}  of  {len(train_dataloader)}.    Elapsed: {elapsed}.    Training Loss: {total_train_loss/step}.')\n",
        "\n",
        "      b_input_ids = batch[0].cuda()\n",
        "      b_input_mask = batch[1].cuda()\n",
        "      b_labels = batch[2].cuda()/10\n",
        "      '''\n",
        "      loss, logits = model(b_input_ids,\n",
        "                          token_type_ids=None,\n",
        "                          attention_mask=b_input_mask,\n",
        "                          labels=b_labels,\n",
        "                          return_dict=False)\n",
        "      '''\n",
        "      preds=model(b_input_ids,b_input_mask)\n",
        "      loss = criterion(preds.squeeze().cuda(), b_labels)\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      del b_input_ids,b_input_mask,b_labels\n",
        "\n",
        "      model.zero_grad()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Perform a backward pass to calculate the gradients.\n",
        "      loss.float().backward()\n",
        "\n",
        "      # Clip the norm of the gradients to 1.0.\n",
        "      # This is to help prevent the \"exploding gradients\" problem.\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      # Update parameters and take a step using the computed gradient.\n",
        "      # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "      # modified based on their gradients, the learning rate, etc.\n",
        "      optimizer.step()\n",
        "\n",
        "      # Update the learning rate.\n",
        "      #scheduler.step()\n",
        "\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    torch.save(model.state_dict(), f'imdb_{epoch}.pt')\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_loss = 0\n",
        "    total_eval_r2=0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for step,batch in enumerate(validation_dataloader):\n",
        "\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].cuda()\n",
        "        b_input_mask = batch[1].cuda()\n",
        "        b_labels = batch[2].cuda()/10\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            preds=model(b_input_ids,b_input_mask).cuda()\n",
        "\n",
        "        loss = criterion(preds.squeeze(), b_labels)\n",
        "        total_eval_r2+=r2_score(preds,b_labels)\n",
        "\n",
        "        del b_input_ids,b_input_mask,b_labels\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    avg_val_r2=total_eval_r2/ len(validation_dataloader)\n",
        "\n",
        "    print(\"  RMSE: {0:.2f}\".format(avg_val_loss**0.5))\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. R2':avg_val_r2,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "outfile = open('training_stats','wb')\n",
        "pickle.dump(validation_dataloader,outfile)\n",
        "outfile.close()\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "validation_loss=[]\n",
        "training_loss=[]\n",
        "\n",
        "for epoch in training_stats:\n",
        "  validation_loss.append(epoch['Valid. Loss'])\n",
        "  training_loss.append(epoch['Training Loss'])\n",
        "\n",
        "plt.plot(training_loss)\n",
        "plt.plot(validation_loss)\n",
        "plt.title('Model loss during training')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.xticks(ticks=[1,2,3,4])\n",
        "plt.xlim((0.8,4.1))\n",
        "plt.ylim((0,0.05))\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Ejbq2MOYpioQ",
        "outputId": "13aebb7d-0b36-4a58-9dc1-2ef0bdd2f2e7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#               Testing\n",
        "# ========================================\n",
        "# After the completion of each training epoch, measure our performance on\n",
        "# our validation set.\n",
        "\n",
        "print(\"\")\n",
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "total_test_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "# Testing dictionary\n",
        "testing_stats={'0.1':[],'0.2':[],'0.3':[],'0.4':[],'0.5':[],'0.6':[],'0.7':[],'0.8':[],'0.9':[],'1.0':[]}\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for step,batch in enumerate(test_dataloader):\n",
        "\n",
        "\n",
        "    # Unpack this training batch from our dataloader.\n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids\n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels\n",
        "    b_input_ids = batch[0].cuda()\n",
        "    b_input_mask = batch[1].cuda()\n",
        "    b_labels = batch[2].cuda()/10\n",
        "\n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which\n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        preds=model(b_input_ids,b_input_mask).cuda()\n",
        "\n",
        "    for pred,label in zip(preds,b_labels):\n",
        "      testing_stats[str(round(label.item(),1))].append(pred)\n",
        "\n",
        "    loss = criterion(preds.squeeze(), b_labels)\n",
        "\n",
        "    del b_input_ids,b_input_mask,b_labels\n",
        "\n",
        "    # Accumulate the validation loss.\n",
        "    total_test_loss += loss.item()\n",
        "    \n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "\n",
        "print(\"  RMSE: {0:.2f}\".format(avg_test_loss**0.5))\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "testing_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_test_loss))\n",
        "print(\"  Test took: {:}\".format(testing_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwwgX1XItbNM",
        "outputId": "b5affe4e-2a71-42a2-f1ba-2b4072e3547f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Testing...\n",
            "  RMSE: 0.13\n",
            "  Test Loss: 0.02\n",
            "  Test took: 0:06:58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y_FmyYC0zL9",
        "outputId": "dc70f336-a91c-48a3-b32a-7f0866831e79"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01757990988089914"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.lines import Line2D\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "data=[]\n",
        "for rating in testing_stats:\n",
        "  data.append(torch.tensor(testing_stats[rating]).cpu()*10)\n",
        "\n",
        "\n",
        "meanlineprops = dict(linestyle='--', linewidth=1)\n",
        "flierprops = dict(marker='o', markerfacecolor='blue', markersize=1,\n",
        "                  markeredgecolor='none')\n",
        "plt.yticks(ticks=[1,2,3,4,5,6,7,8,9,10])\n",
        "plt.hlines([1,2,3,4,5,6,7,8,9,10],0,11,linestyles='--',linewidth=0.3,color='grey')\n",
        "plt.boxplot(data,meanline=True,showmeans=True,meanprops=meanlineprops,flierprops=flierprops)\n",
        "\n",
        "plt.xlabel('Target Rating')\n",
        "plt.ylabel('Predicted Rating')\n",
        "plt.title('Rating accuracy across ratings')\n",
        "\n",
        "legend_elements = [Line2D([0], [0], color='g',linestyle='--', lw=1, label='Median'),Line2D([0], [0], color='orange', lw=1, label='Mean')]\n",
        "plt.legend(legend_elements,['Mean','Median','Outliers'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "m-uBeLMsrdq8",
        "outputId": "68602d8d-bc4e-4b72-f8ad-675c7c624586"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RatingPredictor():\n",
        "    def __init__(self,model,tokenizer):\n",
        "      self.model=model.eval()\n",
        "      self.tokenizer=tokenizer\n",
        "\n",
        "    def predict(self,review):\n",
        "      encoded_dict = self.tokenizer.encode_plus(\n",
        "                        review,                      # Sentence to encode.\n",
        "                        truncation=True,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids=encoded_dict['input_ids']\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_mask=encoded_dict['attention_mask']\n",
        "\n",
        "      preds=model(torch.tensor([input_ids]).cuda(),torch.tensor([attention_mask]).cuda())\n",
        "\n",
        "      return round(preds.item()*10)\n",
        "      \n"
      ],
      "metadata": {
        "id": "JntqsKo22xyO"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor=RatingPredictor(model,tokenizer)\n",
        "review=input(\"Type a review: \\n\")\n",
        "prediction=predictor.predict(review)\n",
        "print(f'Predicted rating: {prediction}/10')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJukclml2igz",
        "outputId": "5c4ec704-acd4-4584-c888-15756ceb2d73"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type a review: \n",
            "The new Batman movie is good, but it doesn't hold a candle to the Christopher Nolan movies. The action is fantastic, and Robert Patinson does a good job, bud you can't shake the feeling that you've seen it before. The psychological aspect was done better in the Dark Knight, and the villain just feels like a Joker rip off. All that said, as a movie it still delivers thrills, and I would recommend it to fans of comic movies.\n",
            "Predicted rating: 7/10\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_training_and_testing",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxk+uEsbSvHhNYKhBoV7BW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "906112e0be7f429abe568b7a9214445c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_897a1cdd8bdf4e27a1238b0b8a0815a3",
              "IPY_MODEL_0bd341f61cd04355b181dd2acea22b15",
              "IPY_MODEL_270da281a6864e9096eca830d874f651"
            ],
            "layout": "IPY_MODEL_bbba5f407a3b482caf6fcc4577303810"
          }
        },
        "897a1cdd8bdf4e27a1238b0b8a0815a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d6bdf34b81e4c8980e0a2c93b7389c9",
            "placeholder": "​",
            "style": "IPY_MODEL_5e453e68e6e042908b85671391874438",
            "value": "Downloading: 100%"
          }
        },
        "0bd341f61cd04355b181dd2acea22b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2864b06d6a634bdc825a371b85c2b982",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_725aca6f9e8f4d218d49443c6b223c04",
            "value": 231508
          }
        },
        "270da281a6864e9096eca830d874f651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59195cc6b0fa42d18f1e61c077ec08fc",
            "placeholder": "​",
            "style": "IPY_MODEL_8ee2b94292de4306b20d12095cc5e6d5",
            "value": " 226k/226k [00:00&lt;00:00, 842kB/s]"
          }
        },
        "bbba5f407a3b482caf6fcc4577303810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6bdf34b81e4c8980e0a2c93b7389c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e453e68e6e042908b85671391874438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2864b06d6a634bdc825a371b85c2b982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725aca6f9e8f4d218d49443c6b223c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59195cc6b0fa42d18f1e61c077ec08fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee2b94292de4306b20d12095cc5e6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "431a32e586c24e4e829c60d50b814189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_957c331314104fe6b1414735d785cdb8",
              "IPY_MODEL_f30ad49bae954144b2761408490ac98d",
              "IPY_MODEL_10009b0caefa4071922efa05be6f4f7f"
            ],
            "layout": "IPY_MODEL_65546b861ea94afcb33be9bb710c6df3"
          }
        },
        "957c331314104fe6b1414735d785cdb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0f131e534114e039943075176dc0e35",
            "placeholder": "​",
            "style": "IPY_MODEL_0b1abb19f21348bd84e0908f9dbebdd0",
            "value": "Downloading: 100%"
          }
        },
        "f30ad49bae954144b2761408490ac98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bc53f859d6b44989b5086b9cebac42a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ed8ed5f83974ae2a8fc1f988171587e",
            "value": 112
          }
        },
        "10009b0caefa4071922efa05be6f4f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7996d0958d1447888652cb367ef02ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_ab2414fdb9024792a171af41177ec089",
            "value": " 112/112 [00:00&lt;00:00, 3.57kB/s]"
          }
        },
        "65546b861ea94afcb33be9bb710c6df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f131e534114e039943075176dc0e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1abb19f21348bd84e0908f9dbebdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bc53f859d6b44989b5086b9cebac42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed8ed5f83974ae2a8fc1f988171587e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7996d0958d1447888652cb367ef02ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab2414fdb9024792a171af41177ec089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51cac2b690d449c9babd8713b8f87d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05734230883840bfad594b807c9d95ce",
              "IPY_MODEL_fefdd3b61848485497ec0f64e0bc680a",
              "IPY_MODEL_218cb5cac3234846af57d7b6d3cb779a"
            ],
            "layout": "IPY_MODEL_b2d177ccbb3f4096943295da6b94ae73"
          }
        },
        "05734230883840bfad594b807c9d95ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d49751bdb84826a889e6815e30aa48",
            "placeholder": "​",
            "style": "IPY_MODEL_281b7351795048f39335c1de18df3d75",
            "value": "Downloading: 100%"
          }
        },
        "fefdd3b61848485497ec0f64e0bc680a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9add6f55e9494a2696c2655ece60eb9e",
            "max": 321,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23596eb47542415d8eb20bac31cf438a",
            "value": 321
          }
        },
        "218cb5cac3234846af57d7b6d3cb779a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62c1c9d71e134147915f43581c7e1df7",
            "placeholder": "​",
            "style": "IPY_MODEL_71c59b54b2b04cbdbdb959f2a2d03496",
            "value": " 321/321 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "b2d177ccbb3f4096943295da6b94ae73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d49751bdb84826a889e6815e30aa48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281b7351795048f39335c1de18df3d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9add6f55e9494a2696c2655ece60eb9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23596eb47542415d8eb20bac31cf438a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62c1c9d71e134147915f43581c7e1df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71c59b54b2b04cbdbdb959f2a2d03496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afbb6124bd9645b4a421f3b04fd5188b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3279a0eb8d80442897ef37672419d6ce",
              "IPY_MODEL_be68f72c05e146b1aeb427086ecda3b7",
              "IPY_MODEL_895cfe45e2694195b32cc06b840924da"
            ],
            "layout": "IPY_MODEL_7f7d68cb90c3466da2803842d92fc680"
          }
        },
        "3279a0eb8d80442897ef37672419d6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50dec81c666448c895ae760c0e67edf5",
            "placeholder": "​",
            "style": "IPY_MODEL_3874d0e6b13d48028d10887c2ff29f94",
            "value": "Downloading: 100%"
          }
        },
        "be68f72c05e146b1aeb427086ecda3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5320741ce4834d218121bcb538a698c8",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84fcc1be04b14d2d921857459bbbb1fe",
            "value": 727
          }
        },
        "895cfe45e2694195b32cc06b840924da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88116fb495d34fdca0e923b0e2cc1be2",
            "placeholder": "​",
            "style": "IPY_MODEL_de37f16538324664adbf322a823290c0",
            "value": " 727/727 [00:00&lt;00:00, 21.1kB/s]"
          }
        },
        "7f7d68cb90c3466da2803842d92fc680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50dec81c666448c895ae760c0e67edf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3874d0e6b13d48028d10887c2ff29f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5320741ce4834d218121bcb538a698c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fcc1be04b14d2d921857459bbbb1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88116fb495d34fdca0e923b0e2cc1be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de37f16538324664adbf322a823290c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0158b3f01b094d0c813f90ead328daf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44fb331bcafb49a99f95cebfccf13d72",
              "IPY_MODEL_c239a240375b428d916d4b6728043417",
              "IPY_MODEL_8fb1f09141b6405f957b5e9b080c1f9e"
            ],
            "layout": "IPY_MODEL_9152fe9e09d04d6090819a910c6f0f02"
          }
        },
        "44fb331bcafb49a99f95cebfccf13d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52112e98aa14a308503f9a158fc16c7",
            "placeholder": "​",
            "style": "IPY_MODEL_c2d85ee3f31f405ba896b34193b70b4f",
            "value": "Downloading: 100%"
          }
        },
        "c239a240375b428d916d4b6728043417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2cdbc6faf94a94894b5a53df4e4516",
            "max": 438024063,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82bdc76fcfcd49649a12efe18d51d3a0",
            "value": 438024063
          }
        },
        "8fb1f09141b6405f957b5e9b080c1f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1501bcd8dd064f50aafd8c38dfbb46d4",
            "placeholder": "​",
            "style": "IPY_MODEL_8c9b85a865f3475a8f1afff7d2625a94",
            "value": " 418M/418M [00:26&lt;00:00, 25.1MB/s]"
          }
        },
        "9152fe9e09d04d6090819a910c6f0f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52112e98aa14a308503f9a158fc16c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d85ee3f31f405ba896b34193b70b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d2cdbc6faf94a94894b5a53df4e4516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82bdc76fcfcd49649a12efe18d51d3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1501bcd8dd064f50aafd8c38dfbb46d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9b85a865f3475a8f1afff7d2625a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}